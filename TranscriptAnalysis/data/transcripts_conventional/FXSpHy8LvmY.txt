FXSpHy8LvmY
https://www.youtube.com/watch?v=FXSpHy8LvmY
Unknown Category
In this video, we're going to talk about a way to develop a feedback controller for a model that's represented using state space equations. And we're going to do that with a method called pole placement, or full state feedback. Now my experience is that pole placement itself isn't used extensively in industry. You might find that you're using other methods like LQR or H infinity more often. However, pole placement is worth spending some time on because it will give you a better understanding of the general approach to feedback control using state space equations. And it's a stepping stone to getting to those other methods. So I hope you stick around. I'm Brian, and welcome to a MATLAB Tech Talk. To start off, we have a plant with inputs U and outputs Y. And the goal is to develop a feedback control system that drives the output to some desired value. A way you might be familiar with doing this is to compare the output to a reference signal to get the control error. Then you can develop a controller that uses that error to generate the input signals into the plant with the goal of driving the error to zero. This is the structure of the feedback control system that you would see if you were developing, say, a PID controller. But for pole placement, we're going to approach this problem in a different way. Rather than feedback the output Y, we're going to feedback the value of every state variable in our state vector. Now we're going to claim that we know the value of every state, even though it's not necessarily part of the output Y. And we'll get to that in a bit. But for now, assume we have access to all of these values. We then take the state vector and multiply it by a matrix that is made up of a bunch of different gain values. And the result is subtracted from a scaled reference signal. And this result is fed directly into our plant as the input. Now, you'll notice that there isn't a block here labeled controller, like we have in the top block diagram. In this feedback structure, this whole section is the controller. And pole placement is a method by which we can calculate the proper gain matrix to guarantee system stability. And the scaling term on the reference is used to ensure that steady state error performance is acceptable. I'll cover both of these in this video. But first we need some background information. In the last video we introduced the state equation x dot equals ax plus bu. And we showed that the dynamics of a linear system are captured in this first part, ax. The second part is how the system responds to inputs, but how the energy in the system is stored and moves is captured by the ax term. So, you might expect that there is something special about the A matrix when it comes to controller design. And there is. Any feedback controller has to modify the A matrix in order to change the dynamics of the system. And this is especially true when it comes to stability. The eigenvalues of the A matrix are the poles of the system. And the location of the poles dictate stability of a linear system. And that's the key to pole placement. And then we can calculate the required closed loop stability by moving the poles, or the eigenvalues, of the closed loop A matrix. Now I want to expand a bit more on the relationship between poles and eigenvalues and stability before we go any further, because I think it will help you understand exactly how pole placement works. For this example, let's just start with an arbitrary system and focus on the dynamics, the A matrix. We can rewrite this in non-matrix form so it's a little bit easier to see how the state derivatives relate to the states. In general, each state can change as a function of the other states. And that's the case here. x.1 changes based on x2, and x.2 changes based on both x1 and x2. And this is perfectly acceptable. But it makes it a little hard to visualize how eigenvalues are contributing to the overall dynamics. So what we can do is transform the A matrix into one that uses a different set of state variables to describe the system. This transformation is accomplished using a transform matrix, whose columns are the eigenvectors of the A matrix. And what we end up with after the transformation is a modified A matrix consisting of the complex eigenvalues along the diagonal and zeros everywhere else. Now, these two models represent the exact same system. They have the same eigenvalues and the same dynamics. It's just the second one is described using a set of state variables that change independently of each other. When the A matrix is written in diagonal form, it's easy to see that what we're left with is a set of first order differential equations where the derivative of each state is only affected by that state, and nothing else. And here's the cool part. The solution to a differential equation like this is in the form z equals a constant times e to the lambda t, where lambda is the eigenvalue for that given state variable. Okay, let's dive into this equation a little bit more. z in shows how the state changes over time given some initial condition, c. Or another way of thinking about this is that if you initialize the state with some energy, or you add energy from an external input, this equation shows how that energy changes. And by changing lambda, you can affect how the energy is dissipated, or in the case of an unstable system, how the energy grows. So let's go through a few different values of lambda so you can visually see how energy changes based on the location of the eigenvalue within the complex plane. If lambda is a negative real number, then this is a stable eigenvalue since the solution is e raised to a negative number, and any initial energy will dissipate over time. But if it's positive, then it's unstable because the energy will just grow over time. And if there's a pair of imaginary eigenvalues, then the energy in this mode will oscillate, since e raised to an imaginary number produces sines and cosines. And any combination of the two, of real and imaginary numbers, will produce a combination of oscillations and exponential energy dissipation. Now I know this was all very fast, but hopefully it made enough sense that now we can state the problem we're trying to solve. If our plant has eigenvalues that are at undesirable locations in the complex plane, then we can use pole placement to move them somewhere else. Now certainly if they're in the right half plane it's undesirable since they'd be unstable, but undesirable could also mean there's oscillations you want to get rid of, or maybe just speed up or slow down the dissipation of energy in a particular mode. With that behind us, we can now get into how pole placement moves the eigenvalues. Remember the structure of the controller that we drew at the beginning? Well this results in an input u equals rkr minus k times x, where rkr is the scaled reference, which again we'll get to in a bit, and kx is the state vector that we're feeding back multiplied by the gain matrix. Now here's where the magic happens. If we plug this control input into our state equation, we're closing the loop and we get the following state equation. Notice that a and minus bk both act on the state vector, so we can combine them to get a modified a matrix. This is the closed loop a matrix, and we have the ability to move the eigenvalues by choosing an appropriate k. And this is easy to do by hand for simple systems. Let's try an example with a second order system with a single input. We can find the eigenvalues by setting the determinant of a minus lambda i to 0, and then solve for lambda. And they're at minus 2 and plus 1. One of the modes will blow up to infinity because of the presence of the positive real eigenvalue, and so the system as a whole is unstable. Let's use pole placement to design a feedback controller that will stabilize this system by moving the unstable pole to the left half plane. Our closed loop A matrix is A minus Bk, and the gain matrix k is a 1 by 2 since there's one output in two states. This results in minus k1, 1 minus k2, 2, and minus 1. And we can solve for the eigenvalues of ACL like we did before, and we get this characteristic equation that's a function of our two gain values. Now let's say that we want our closed loop poles at minus 1 and minus 2. In this way, the characteristic equation needs to be lambda squared plus 3 times lambda plus 2 equals 0. And at this point, it's straightforward to find the appropriate k1 and k2 that make these two equations equal. We just set the coefficients equal to each other and solve. And we get k1 equals 2 and k2 equals 1. And that's it. If we place these two gains in the state feedback path of this system, it will be stabilized with eigenvalues at minus 1 and minus 2. Walking through an example by hand I think gives you a good understanding of pole placement and how it works. However, the math involved starts to become overwhelming for systems that have more than two states. The idea is the same, just solving the determinant becomes impractical. But we can do this exact same thing in MATLAB with pretty much a single command. I'll show you quickly how to use the place command in MATLAB by recreating the same system that we just did by hand. I'll define the four matrices, and then create the open loop state space object. I can check the eigenvalues of the open loop A matrix just to show you that there is in fact that positive eigenvalue that causes the system to be unstable. And that's no good. So let's move the eigenvalues of the system to minus 2 and minus 1. Now solving for the gain matrix using pole placement can be done with the place command. And we get gain values of 2 and 1 just like we expected. Now the new closed loop A matrix is A minus BK. And just to double check, this is what ACL looks like, and it does have eigenvalues at minus 1 and minus 2. OK. I'll create the closed loop system object, and now we can compare the step responses for both. The step response of the open loop system is predictably unstable. And the step response of the closed loop system looks much better. However, it's not perfect. Rather than rising to 1 like we would expect, the steady state output is only 0.5. And this is finally where the scaling term comes in on the reference. So far we've only been concerned with stability, and have paid little attention to steady state performance. But even addressing this is pretty straightforward. If the response of the input is only half of what you would expect, why not just double the input? And that's pretty much what we do. Well, we're not just doubling it. We scale the input by the inverse of the steady state value. In MATLAB we can do this by inverting the DC gain of the system. You can see that the DC gain is 0.5, and so the inverse is 2. Now we can rebuild our closed loop system by scaling the input by kr, or by 2, and checking the step response. And no surprise, its steady state value is 1. And that's pretty much what there is to basic pole placement. We feedback every state variable and multiply them by a gain matrix in such a way that the closed loop eigenvalues are what we want, and then we scale the input to make the steady state response what we want. Of course there's more to pole placement than what I could cover in this 12 minute video. And I don't want to drag this on too long, but I also don't want to leave this video without addressing a few more interesting things for you to consider. So in the interest of time, let's blast through these final thoughts lightning round style. Are you ready? Let's go. Pole placement is like fancy root locus. With root locus, you have one gain that you can adjust that can only move the poles along the locus lines. But with pole placement, we have a gain matrix that gives us the ability to move the poles anywhere in the complex plane, not just along single dimensional lines. A two-state pole placement controller is very similar to a PD controller. With PD, you feed back the output and generate the derivative within the controller. With pole placement, you are feeding back the derivative as a state, but the results are essentially the same. Two gains, one for a state, and one for its derivative. Okay, we can move eigenvalues around, but where should we place them? The answer to that is a much longer video, but here are some things to think about. If you have a high order system, consider keeping two poles closer to the imaginary axis than the others so that the system will behave like a common second order system. These are called dominant poles since they are slower and tend to dominate the response of the system. Keep in mind that if you try to move a bunch of eigenvalues really far left in order to get a super fast response, you may find that you don't have the speed or authority in your actuators to generate the necessary response. This is because it takes more gain, or more actuator effort, to move the eigenvalues further from their open loop starting points. Full state feedback is a bit of a misnomer. You are feeding back every state in your mathematical model. But you don't, and can't, feed back every state in a real system. For just one example, at some level all mechanical hardware is flexible, which means additional states, but you may choose to ignore those states in your model and develop your feedback controller assuming a rigid system. The important part is that you feed back all critical states to your design, so that your controller will still work on the real hardware. You have to have some kind of access to all of the critical states in order to feed them back. The output Y might include every state, in which case you're all set. However, if this isn't the case, you will either need to add more sensors to your system to measure the missing states, or use the existing outputs to estimate or observe the states you aren't measuring directly. In order to observe your system, it will need to be observable. And similarly, in order to control your system, it needs to be controllable. I'll see you next time. Thank you.
Superb video‚ù§

When i add the file into ultimaker cura it shows the whole thing and it not in pieces

I'm new to 3d printing. I got the head file. How do I separate each piece to print?

Very cool - thank you for sharing :)

Thanks.  I think that I can tweak your code to provide acceleration to a stepper motor.

This is beautiful. I will try to make one following your tutorial. Thanks üôèüèæ

Are servos controlled in position or in speed?

super lit

I hat not 3d printer so how manke robto all parts

stl ?

I'm looking to get animatronic eyes, and want to learn how to make them too. I have a question. Can you program the eyes to do certain tasks randomly or in a sequence that suggests autonomy?  No use of a joystick. You video is 2 years old. I don't know if you read these replies. I should mention, I don't have a 3D printer. A few years ago, I found a website where they print what you want. You just have to send them the file.  I see various links on the description. I'll explore that in a minute. Just curious about the programming.

can you give me the 3d files please

FNAF

I‚Äôm not even 13 and I did this

Bender‚Äôs head ‚ù£Ô∏è

Awesome!

New william afton

Nice video!

Is there a website to build and make a motherboard

FNaF (sorry)

FNaF (sorry)

Mind sharing the cad files? The one in the description of the video is not printable. All the body's are attached to each other.

0:04 afton if he was brutally glued to the suit

stl files ??????

I usually dont really comment on a yt video. But this one just blows my mind. how simple yet elegant...really amazing. keep going üòä‚ù§Ô∏èüî•

Everyone gangsta till he needs a security guard

dont ask why but i want to print a freddy head to go on top of this

Does a guy named 'William Afton' do this too? I don't know him but i have heard he made pretty good animatronics.

Beautiful. ‚ù§

I didn't know William Afton was doing a tutorial

Hello, could someone tell me where to get the model to print?

WHAT THE ACTUAL HELL AM I LOOKING AT. THATS BLOODY FREAKY!

very good . the smoothing ist good with the rotation but it does not fit eye motion. eyes and blinking works very rapidly.

Don‚Äôt forget space for the children üòÇ

Some of it is hard for me to comprehend, more of the electrical and the wiring/programming, any tips on what I could do to learn how to build something similar? Would it be wise to take like a robotics class because i just feel like if i had someone to talk to in person it would be easier to understand

FANTASTIC! THANK YOU SO MUCH 4 SHARING!

üòäüòäüòäüòä

bro is making a fnaf animatronic

Is it maybe posible to use not printed stuff like wood i really want to do a project but i dont have a 3d printer and also dont have any servoes or anything so could you make a seprate video explaini g the reqweirments?

i wanted try this project out, but the stl files in the github account show as just one assembled file as opposed to several individual printable pieces.  is there a way to get ahold of individual files?

Yes that is the whole assembly, you need to import that into some CAD software and extract the parts from there in whatever format you wish - just like if you drew them yourself in CAD.

@jamesbruton¬†  When I try to import the file into FreeCAD, the file only splits it into 3 large sections, not the parts that make up those large sections, and there is no way to manually split them farther, as the program considers it one object.

Need help mate?

nvm i figured it out!

Plz build me a johnny 5 talking head üôèüò¢

It's best practise in coding to never use hard delays in the main loop. For a simple demo or test it can be forgiven. In essence it should turn off completely, if doing nothing. Maybe it will store stuff from what happens and retrieve it when waking up again and we can have extra micro controllers on the side, if something must continue, such as "waking up."

What is the app called?

Great video.how do u prevent the servos from jumping on the moment of powering the system overall?.that is a challenge why robotic companies use either encoder or stepper motors instead of servo which needs to default position upon start. Can u solve this ?

TLDR: recursive filtering

Any stl files for the 3d printing, I was going to try and make this?

What about the moving mouth?

A nice formula for smoothing: time = time * time * (3 - 2 * time)  I wonder if the arduino could handle that, because you could create a really nice smooth step function with that ü§î

You could take this one step further and integrate this with 3d animation software. Blender has great python scripting functionality that can not only get the data in and out easily, but also take into consideration the max speed of the servos and warn the animator they are approaching a limitation. I'm sure Disney and Universal do that with their animatronics these days too with Maya or something.

Do you sell things like that?

Is it possible to make it so it follows you by using a face detection code?

hor hor hor hor

nice now im gonna start a family pizzeria business with animatronic that dont have kids corpse inside the animatronic :)

I just try to access to the Cads Models but it¬¥s empty. Could you be so kind to facilitate the models to print? Thanks in advance and awesome work!

amazing!

Would if I just wanted to write a servo position without using a joystick? For instanv=ce: have a servo go from position of 90(or 1500) to 180 and decelerate as it reaches the 180 position? Thanks!

What kind of control is this? Proportional and integrative?

What if instead of an eye this was a light for my bike controlled by a gyro sensor in my helmet?

This technique will work properly only for actions which have a relatively long duration. Fast inputs will yield virtually no response from the servos. You must add the smoothing attenuation coefficient for high speed inputs.

Have you hacked Siri or Open AI yet to contol your creatures ? Do they talk to oneanother ?

PLS PUT THE 3D MODEL!!!!!

wow! fnaf is coming to life now! im going to make the pizzaris!

FNAF fans coming to learn how to make animatronics?

Hi James, I loved your project and I would love to print it, would you have the files in STL? Could you provide them to me?

holy cow when you connected the joysticks it really brought him to life with smooth motion. thanks for such a cool video!

Can you post the files

The size of the those eyes remind me of freddy fazbears eyes size

I Just started to mount one with your files. Thank you, thank you!!! Tomorrow it will be completed.

‚Äú*FNAF*‚Äù

What‚Äôs the name of the website I see every arduino user use for the prototype models?

Could any one please tell me how to save separate .STL files using .stp file that provided here. Thank you

Where can i find a 3d models for printing used in your video?

That's awesome, looks like a muppet show character but moved by mechanics.

The truth is it's very nice but the question is... what will you do with that robot after it is 100% completed? Are you thinking of selling it or something like that?

o cholera czy to freddy fazbear

When i see the head i think of endo 02

Is this the start of 87

Are the 3d models public? If not please could you make them public? Or put them for sale on one of your shops

I thought Ai could solve this issue with anticipation mathematics

Does the code make it so that it moves on its own? And can you show me how to remkved the code for the neck and keep the code for the eyes only

Heheheh

guilty üò©

Here‚úãÔ∏è

me

That is the whole assembly - you need to load that into some CAD software and it'll appear like you drew it. You can modify it or export the individual parts are STLs or whatever format you wish.

Link in the description

Okay

animatronics aren‚Äôt just fnaf but sure

Yes

Sounds good

FIVE NIGHTS AT FREDDYS

Instructions unclear, my animatronic is trying to stuff me in a mascot costume

Very nice project.   A little tip ;)   You could implement the setSequencer (10:05)  using a switch / case to avoid if/else statements and in future projects with more steps, use a Design pattern like state machine.  Using switch/case could be something like this:   void stepSequencer() {     int ellapsedTime = currentMillis - previousMillis;     bool changeStep = false;          switch(stepFlag)     {         case 0:             if (ellapsedTime <= 500) break;             pot1 = 512;              pot6 = 512;              changeStep = true;             break;         case 1:             if (ellapsedTime <= 1000) break;             pot1 = 1024;              pot2 = 1024;             pot6 = 0;             changeStep = true;             break;         case 2:             if (ellapsedTime <= 1500) break;             pot1 = 0;             pot2 = 0;             pot6 = 1024;             changeStep = true;             break;         case 3:             if (ellapsedTime <= 1500) break;             pot2 = 512;             pot5 = 512;             pot6 = 0;             changeStep = true;             break;       /// Other steps       default:                // Maybe restart the steps              stepFlag = 0;              break;     }      if(changeStep)     {         ++stepFlag;         previousMillis = currentMillis;     } }

Linear Interpolation (lerp)

Oooooh,I watch ‚ÄúHenricksworkshop‚Äù

Quit trying to make fnaf real this is gonna end up like Jurassic park

The average furby and fnaf animatronics üíÄ

is this where you wanna be

00:15 0_0

Nice one! Just dont stuff kids into these animatronics i dont think it will end well.

African American robot ?

WHERE IS FNAF FANS

0:10 it looks like fnaf

I think the jerky motion is kind of a hallmark of animatronics in general. it gets a little... uncanny if you make them move too smoothly. I mean, then you get some iRobot looking stuff... and, I shudder to even think of that

pay attention to how  you move your eyes, eyes  dart  they don't  move  smoothly.

Nice, the movement at the end looks nice and smooth. But please, STOP using servos in humanoid robotics...  Servos are needed for accuracy. Our muscles don't care about accuracy. they either contracted, or relaxed.  Human limbs are closer to async motors - it either accelerates or moves by inertia.  Both accuracy and speed are achieved by constant tactile feedback, and short contraction of different muscles in different directions.  Also the smoothness is achieved by control over contraction and inertia times, depending on feedback, and desired result.

This guy making legit a fnaf Anematronic

Dear god

Awesome.  Could you use ultrasonic sensors to create a 3D map

AI ROBOT

tika muchkond hogo le lowde

i just dont get it, why do you want to stay

Can‚Äôt wait for racially diverse necrons and eldar!! Hope the space marine realises he‚Äôs actually a woman at the end. Yup, this‚Äôll be epic

eyeballs actually have a more rigid movement when compared to the rest of the boy

Is there a link to that 3d print model?

Why didn't you just use 2 servos for the eyes and eyelids? Both eyes look in the same direction anyways, it would use less power and be lighter

Thanks for this tutorial, I‚Äôm gonna use this for the animatronics for a place called Freddy fazbears pizza

For my part I would have made the deceleration as minimal as possible, so that the movement is as fast as it can be without perceptible jitter - I would have liked to see those tweaks.

This will be something during an Incident at a Family Pizzeria.

Where do you buy the mechanical parts

We making fnaf

hello, could you show me the diagram of the drivers needed for the servomotors?, the one on the breadboard, thanks

har har har har har

Like these projects a lot Thank you Jean-Fran√ßois

Pls share the 3D stl flies for this robot eyes

Great tutorial James!! Have you done any tutorials on implementing a 6DOF board?  I‚Äôm interested in how it is used to compensate servo movement/positioning like for a self leveling robot.

Anyone else clicked on this because it looked like an endo skeleton

FNAF fans

afton robotics

This is rearly cool (and totally doesn‚Äôt look like a fnaf endo)

Bro, literally said, do you know what I‚Äôm gonna make an endoskeleton from security breachüíÄ

Thanks i have my ovvn sleep paralysis demon novv ( Yay...)

Very nice, now I need this scale 1:3    :(

William is listening

This looks like a heavily simplified version of a PID controller. If this is a step in the right direction for your project but doesn't give you quite the amount of control you need, consider looking into PID controllers, they're very cool and surprisingly simple.

DON'T GIVE ANY FNAF FAN IDEAS DONT DO IT

Its giving fnaf

I'm working on a clone of this using Jetson Nano  https://youtu.be/R222qYnYFEY

FIVE NIGHT AT FREDDIES

Can you make a video on how to make an Arduino record an animation with push buttons and then play it back?

This is like fnaf endo

James Afton.

The thumbnails animatronic looks like a endoskeleton from FNaF

Good one. Remember to keep the teeth rubber, you know what happened back in '83 right?

I know this is old, but I'm in progress of making this.  My version will have face tracking via depthai.  And powered by openai API.  Love this version of animatronic eyes.  thanks for such a great design.  And thanks for posting the CAD!

You sound like davehax

Ugly robots from hell. Every robots are computeriezd by human.

üíÄüíÄüíÄüíÄüíÄüíÄ

Is no one going to talk about the fact that it looks like a fnaf security breach endoskeleton

Where can I download this 3d model of endoskeleton head?

Fnaf

Thanks for telling how 2 five nighter at ferdinand bon venard eyes

Yes thanks, I have a whole playlist of balancing robots and vehicles

is it just me or does it kind of look like a blue fnaf endo head with no mouth

add skin and mouthüòÑ

Fnaf in a nutshell

Do they get quirky at night?

Do you have a link to the 3d print files?

bros making fnaf animatronics

üî•üî•üî•üî•üî•

i cllicked this video becuase i saw what looked like an endo :(((

#1 rule for making robots: never make them a wearable suits with springlocks

Love this! Any tips on motion detection - Ideally so the eyes track L to R movement?

It‚Äôs also the title to a terrific song by Three Dog Night! ü§î

kinda creepy but interesting

Is that William Afton??

The word ‚Äúanimatronic‚Äù is forever associated with man killing kids and stuffing them in a robot.. and i love it

I will never work with animatronics like what if they get quirky at night

william afton moment

NEXT WILLIAM AFTON!?!?!?!?

Hello! Thanks for the awesome tutorial. Is it possible to get the STL files somewhere? Maybe i missed in the video but if it wasn't mentioned, i would very much like to acquire the STL files for this model to build it with my son. Thanks a lot.

It's 12:52 am, i've never in my life have made a robot, hell i've never even seen a 3d printer in person, yet i'm still going to watch this as if it's on an exam.

Stuck at 'Bookmark". Not familar with usage. Nor is Cambridge Dictionary. Nice tutorial, Thank you. I used integer muliiplication and integer division for a jittery bar graph in Heidenhain TNC HDMI. smothevalue=(19pld + 1new)/20. Damping increases with multiplier.

Wouldn't it be easier to add a line of algebra to control the movement? Calculating the voltage/current in an equation which defines a parabola with upper and lower limits may be more precise.

I‚Äôm getting some FNaF vibes from this‚Ä¶

FNAF

no one wants to help me....

Is that movement "lifelike" really? I think it looks "artificial". I don't move that way. You can see such movements in 3D cartoon animations for children. Maybe you should increase the percentage of change each millisecond?

Cute

Where are the files

Is this fnaf

KEEP going ma friend

I agree with ramping on everything but the eye movement and eyelids.   We don't ramp our eye movements or lids unless we are super tired...or drunk or stoned.

eyeballs move smoothly when they are following a moving object even if the head is itself moving however, eyeballs move very suddenly when they change the direction they are looking at. place your hands in front of you.  move your right hand around. your eyeballs follow it smoothly. Start moving your head as well. Your eyeballs continue following your hand smoothly. Look at your left hand. Your eyeballs change from looking at your right hand to looking at your left hand in a very sudden movement.  move your hands in opposite circles, left clockwise, right anticlockwise (or the other way around, doesn't matter) look at your left hand then at your right hand. You will notice your eyeballs follow each hand smoothly but transition from left to right hand very suddenly.  You can use a high framerate camera to verify this.

you üé∏

although having gear mechanic set robotic motion having motion set variable algorithm will be a gud help :)

My name is Qui Gon Jinn, you are gifted, would you like to come to the Jedi Temple to begin your training?

one of the GREATEST videos ever, Thanks

Great video as always! I was thinking about it, and if you want to double how organic it can look, you can combine smoothed motion and jerky motion.  For example: say you have your animatronic in a sort of 'sleeping' state, but then you need to 'wake it up'.  At the very beginning, you can take a few approaches, such as being startled. Essentially, start with jerky movement scanning the entire environment very quickly, and then 'calming down' and use the smoothed-out motion.  A lot of this would be easier with pre-programmed movements, especially if you want to quickly switch between jerky and smoothed-out motions to help simulate different emotions and such. You would also need to take into account that humans are hardwired to be incapable of moving their eyes smoothly without tracking an object. Otherwise, the eyes move in a somewhat smooth, but still jerky motion. All of this is just me thinking, and animatronics aren't really my thing, so if you're into this kind of thing, maybe this could be useful to you. Maybe not.  Anyway, great video, and hope you have a good day!

Great Job :D !

One thing I've always noticed since I was a kid at Chuck e cheese is when the robot stops moving suddenly and leads to the whole thing shaking from the sudden stop.

HE DON'T KNOW BUT , HE IS MAKING HIS OWN DEATH

How much would you ask for ur assembled robot?

I don't even have an answer from you

Thank you so much, may god bless you always and youtube.

See, On YouTube : Madame Leota Headstone Comes To Life. ...Where can l purchase something, Like this or close to it, Please?

Newer robots might be able to move smoothly as a human.

Hello, Where did you get your joy sticks from?

Proof of concept but what you did still looks unnatural and is a common mistake. eyes move quicker than necks eyelids are very fast with not much smoothing etc. What you did still makes the object look extremely fake or like a person got knocked out and is trying to wakeup.

Nice video, thank you for the good content.

Could you add face tracking to this instead of remote.

These are called "easing transitions" and there are many different ones for different types of animations. I'd definitely recommend looking up some of the theory on these to help fine tune formulas for different uses.

12:28 lol was really getting into it until this point. skipped the whole soldering and component connection bit.

Absolutely great!

william afton

Nah bros tryin to make an endo üíÄüíÄ

does anyone know how many servos it took for this project

sell these

this video just in my recommended just brought me back to one of my favorite channels from a while ago, used to binge watch your hulkbuster build series trying to figure out what anything you were saying meant

How about magnetism?

low do spiderman

this is really cool

THank you for this!

Isn't it amazing that Five Nights at Freddy's probably got tons of people interested in how real animatronics work? It's kinda fascinating to me! Like, just look at the amount of servos and wires to provide the base head and eye movements!

real life animatronics don't use servos and wires lmfao, the animatronics that chuck e cheese, showbiz pizza, and disney use are a series of hydraulic pistons, and compressed air to move heads, arms, legs, body, and eyes

@realnarwhal¬† yeah, I knew that, but it's interesting how folks still look into it nonetheless. Servos are mentioned in the first FNaF after all, and with the amount of wires poking out of, say, the Withereds, they don't seem to be hydraulic. Besides, I doubt these hydraulic mechanisms could make an animatronic walk, let alone move around.  I mean, I sure as hell have never seen any do it.

im making arms and leggies for a snake, ty ladüíô

Great project. Can you please share the STL files of the 3D print files?

might as well pick up "Animator's Survival Kit" on top of that

Fnaf boutta become real

Why not sell this as a kit?

Hi there, James.  Great video!  Love your eye setup.  I am a 3D printing newbie and am wondering if the plans/code/whatever are available to make my own.  I have a puppet in desperate need.   Cheers.

imagine you add speaker and chatgpt for it, it could speak and eye contact

Don‚Äôt do crack

FNAF !!!

By far the best animatronic 3D printed eye mechanism I've seen. Willing to purchase obj or stl files.

WOW  , I want to learn this !  ‚òÄ‚òÄ‚òÄ‚òÄ‚òÄ  ‚ù§

Bro being purple guyüíÄüíÄüíÄ

I would assume your using Digital Servos and if so, which one?  Are they quiet?

@jamesbruton >>> I just found your channel this morning. Subbed...üëç

im gonna be the next william afton

Congratulations, the joystick control method means you made a 70's Chuck E Cheese mechanism.

Where can I find the 3d model for that?

My guy is William Afton

Hi, first of all great video. I have a question to you, im using esp32, its using map function and send the data via PWM to the servo, there is a way to smooth it like you did?

who's here because they are obsessed with Five nights at freddy's

Any chance you have released the 3D files so others can print it as well?

I really want to get into robotics; making my own FNAF animatronics sounds so cool!

Alternate title: How to turn FNAF 1 animatronics into FNAF 5 animatronics

Fun fact: he used the endo-01 model for the face

The lore of finaf

Hi, how I can contact you, i need some help with one of my project.

Chonky cheems

We are only getting closer to Five Nights at Freddy's.

hi sir can you send me stl files of this project

the eyes should have less smoothing. because they can move a lot faster organically.

#include <Servo.h> // include the Servo library  Servo eyeServo; // create a servo object for the eye  void setup() {   eyeServo.attach(9); // attach the servo to pin 9 }  void loop() {   int position = random(20, 160); // generate a random position between 20 and 160 degrees   eyeServo.write(position); // move the servo to the random position   delay(500); // wait for half a second before moving to a new position } Hope it helped :]

Hi  Suggest  me  from  where i  can  buy the  animatronic plastic components

Do you design your own parts for the 3D printer to make, such as the eyelids and levers, or is there somewhere you download the .obj files from?

I've always wanted to make something like this and I did get my own 3d printer, I just don't know how to model anything that a servo can fit onto :P

too bad I made nun in my lifeüòë

there is some free software for linux to use for drawing?

what is it`s program please write

Very cool! How did you get Piers Morgan to narrate for you?!

Any good suggestions for 3D printers for beginners üòå and is it necessary to have a computer or will I be able to also use just my phone

Thank you so much for the enlightenment! You were the first video that I chose and I'm pretty glad I did üòåü•∞ I've subscribed to your channel and will both definitely be returning!!!

The whole project is on Github and the link is in the description.

@jamesbruton¬† but sir there is no stl file there is a cad folder stb file but i need stl files of all part

@robotics550¬† STP or "Step" files are the universal CAD files that can be opened in pretty much any CAD software including free ones.  A number of slicers like Prusaslicer and Cura (with a plugin) can nowadays also load STP files and should split the parts into individuals components you can then start fitting on your print bed. Alternatively you can use any CAD program like Freecad, Fusion360 and so on to load the step file and then export all parts as STL/3MF files.

@chielvoswijk9482¬† thank you so much

For nearly everything there is a open-source version that also works on linux. In this case: FreeCAD. Not as easy as say Fusion 360, but you can do plenty with it.

The two kings of the user friendly 3D-Printing market are long-established Prusa Research and newcomer Bambulabs. Both of their printers are considered pretty easy to get started with, automating most calibration that tends to cause headaches to newbies.  You are going to need a computer though. To turn a 3D-Model into instructions for a printer to work with, you need to use a "Slicer" that does just that. That is a pretty beefy task that only a PC/Laptop can really take on. The resulting "Gcode" file can then be fed to a 3D-Printer via, network, thumb-drive or SD card  I generally advise one to first try out Slicing first. You can just try out such a program without having an actual printer to get a feel of what it takes to work with a printer, how they work and how long your prints are going to take (spoiler: They ain't fast...). Prusa's own PrusaSlicer is the most popular one as it works with nearly all major printers.

thanks a lot

Can someone explain the two lines of code for smoothing

2 lines of code 12 minutes of video

Muy buenos robots .

Can we get a 3d print file for this thing?

Thank you for making this video now I know how to make smoother Movements and make the eyelids thank you

Really nice video, where is the part list? Thanks üëç

it's important to note that this method of smoothing always adds a bit of delay into the system, so for things that you want to be smooth but still snappy, you'd be better off using a proper easing method which allows you to specify exactly what time it should take to get to its final position, and whether it should ease in or just start immediately like your system does

Are the .stl available to download somewhere?

Learned something cool today, Subscribed.

Hello James, Very impressive work.... i would like to purchase the whole Eye ball movement setup... May i know whether its available ?

James, great video, appreciate as always your attention to detail and sharing the work. Looking at the CAD, I had a question about your process. From what I can tell, looks like your just taking measurements for the servos and building your own vs importing from a library is that right? Curious if that's just to get the dimensions right for print vs actually testing the mechanism through simulation. Thanks again and Cheers!

Can you share the stl files for this build?

Does anyone know what those rotating joysticks are called or where I can get them?

This is very neat, thank you.

STL flies to 3d print it please. Icant find them in the description

Great work,  it really proves that every thing in nature behaves like a logarithmic curve, what you explain here is warping the pulse within a logarithmic curve that shapes the on and off transition instead of having sharp sudden changes.  As per comments below yes, this can also be applied to turning LED on or off to make them glow up or glow down (emulate a candle light for example)  or to shape sounds to create smooth transitions for amplitude or frequency allowing different sound effects .  As someone said below think of all the applications that use pulse width modulation.

9:35 Running all events in an infinite loop is not energy efficient nor is using delay functions,  the best approach I found when i was working with PIC micro controllers is to use an internal  timer TMRO to generate an interrupt at fix intervals and then run all events within such interrupt,  the lapsed time within interrupts the micro controller can be in sleep mode until next interrupt saving big time on battery life.  Now I use ESP32 with RTOS and internally has the same principle with the added feature that each interrupt checks for task priorities on the queue and that's how  multitask operating systems work.  The ATMEL 328 used by arduino uno has 2 internal timers that can allow even more options. I think the loop approach used by Arduino is good for beginners but create really bad habits for embedded programming.  The way to go is to get familiar with interrupts, service interrupts and priorities.

Colombia, muchas gracias ingeniero

it would be very nice to add a camera in one or each of the eyes.

It takes a large amount of the previous value and a small amount of the new value on each code loop, so the output value can't change too much. That output value becomes the previous value on the next code loop.

@jamesbruton¬† Thank you for your quick response üòÜ But I don't really understand why it stops at 100 or why it is smoothing before it reaches 100

Yes link is in description

Yes the link is in the video description.

@jamesbruton¬† thank you

started to see some uncanny valley things when i pictured the front servo arms as human neck muscles

can i hav it

Would it be possible to implement a similar or the same technique for acquiring smoother motions with these MG996 servos for a 5 or 6 DOF robot arm?

Hi, which part of the program do you use to drive multiple servos together at different angles and at different speeds?

That would be great if you could consult/work with 3d animators, because they know all this stuff much better. But still, amazing work

I loved your video. Exceptional work and video has been made really well. Connect with me pls I have something interesting to discuss.

You mean it's not natural to have sharp, sudden and jagged movements? I must ask my creators abou- Er, I mean; Mother and father units if I am actually a real boy like they said I was.

We can make the same FNaF animatronics with tutorial like this)

The easing on those eyelids are so satisfying

https://youtu.be/_4ZA4GZri4w

This really gave me an idea on how I will build Chuck E. Cheese animatronic

eyes need webcameras

ü•∞ü•∞ü•∞ü•∞ü•∞üëèüëèüëèüëèüôåüôåüôåü•∞ü•∞ü•∞ü•∞ü•∞ü§Øü§Øü§Ø, congratulations!

Hello sir... Can i have the link for 3d templatr for the eyes?

You bought it before me I was gonna make an robot but you did it first and I didn‚Äôt have a 3-D printer

it is like using PID? am I right?

shoou , onde baixa o stl desse olho....

Hi, Where can i get the stl file for the prints.

Excellent job Great work where can I find the print stl files thanks

Where i can get tutorial to build animatronic in this video step by step

this is a super cool project tho

i have like 40 of these motors, and nothing to do with them, looks cool, good job, big shout out to james, thanks

I interest with ur amizing project but i newbie in arduino ineed list of electronic part to build it,

James has to keep 3D printing to make use of his free 3D fuel

Is there a tutorial and or product name for the joysticks?

Watch Engineered arts and you'll be happy:)

Can I get these stl files?

Can the same thing be done in Python?

I've been working in my own animatronic for the past 2 months now and one thing I notice is the Eye servos will not stop jityering, I added a Low pass filter circuit thinking it was a data communication issue, it worked for the most part, still being jittery but not as much, I will definitely try and implement this

Really wish I have a giant robot version of irl me :(

It helped me in my arm robot

bruh someone is gonna watch this and make frebby fazbear

Please where do we code it

I love this

I don't have a 3d printer

Fnaf

Did he get the design for the eyes from fnaf? Because they look almost the same as in the game.

Me: wants to make an animatronic Also me: I have no idea what those things he 3d printed are- if i knew it would be easier

eyeball movement should stay unsmoothed

What James has created here is a low pass filter (fast input changes are reduced). This can also be used to reduce 'blips' in analogue values such as reading a light sensor etc. I hope you don't mind but I've pasted a function to do this. Call it with input=the analogue value read (converted to double), and f as the cutoff frequency in Hz (try 0.3). Call it from a timed loop (e.g. reading a value and having a delay (e.g.100ms)  double filter(double input, double f) {   static bool initialise = true;   static double prev_x = 0, prev_y = 0;   double y;   double T;   static unsigned long lastmillis;    T = (millis() - lastmillis) / 1000.00;    //f = 0.2; //Cutoff frequency in Hz, small value makes a slow response   f = f * 2 * PI;   //if (initialise) y = input; else   y = f * T * prev_x + prev_y - f * T * prev_y;   initialise = false;   prev_x = input;   prev_y = y;   lastmillis = millis();   return y; }

How to make its not noisy, silent motion

I would love to see some tutorials about power management/battery integration

Plz make something from fnaf

Check description it's on github

You can't because the servos are pretty cheap

I just fall in love with all your projects

Can you explain a ease in and ease put for movement, increasing less to more vel and decrease for end of the movement, thansk

With how realistic the robot's actions are, it's unexpectedly wholesome.

Could you use a curve that eases at both the foot and the tail, with those eases each separately adjustable? Also I think eyes should not move so smoothly unless they're tracking an object moving through their field of view. I really dig the stuff you build!

control c control v

can you do more tutorial like a fnaf animatronic please

Watch till the end this is amazing

Can you send me 3d printer prints pls I wanna make it

can u give me all 3D print model

you are the best

Nice build and tutorial!  A thought:  Rather than a single, hard-coded acceleration value, have a separate acceleration value for each mechanism based on two values:  1. A 'Mass' variable, as an object's mass will determine how quickly it can accelerate for a given force. 2. A 'Force' variable, as the maximum force that can be applied will determine how quickly it can accelerate for a given mass.  (The ending acceleration should be much less than the initial acceleration, as we tend to use max force to begin movements and much less to end them, for the sake of precision.)  This should allow for highly-nuanced, realistic motion that would, for example, have the head turning MUCH more slowly than the eyes.

Sometimes you want a constant speed approach to the target position, not a fast move at the start & slower toward the end.  In all robot routines I write I have such a routine "standing guard" between the servos & the code outputs to protect the servos from damage.           Routine works like this: like yours, you have target input & existing output.  In addition, you have a maximum allowed step size per iteration.  On each pass, the existing & target are compared.  If the same, do nothing.  If target > existing, add step; if target < existing, subtract step.  This routine alone can step past the target value if step > 1.  this can be prevented by doing the same compare AGAIN after the change.  if the sense of the compare is the same as before (or existing + target), everything is OK.  But if not, set existing = target.  I have code for this which I can show you if you are interested.           For the scheme you have (which is a "first order digital low-pass filter"), you can run into trouble if the math is done in 8-bit format (or even if 16 bit if the multiplier is very small.  When you multiply 8-bit number by small fraction, the product will become 0 long before you have reached the target value.  The filter will "stall" short.  You can fix this by using a table for the multiply, which has 0 output only for the case the difference = 0           You can also run into "dither" as the existing approaches the target because of the different rounding that takes place in the 2 separate multiplies.  The servo will smoothly approach the target, then start wiggling +/- 1 count.  The fix for this is to take the difference between existing & target, do ONE multiply,  & add that to the existing.

Thought of using the servoeasing library ?

Where can I find the parts for the 3D print

I did find a joystick that also has rudder axis. But I just couldn't find a gamepad with 2 joysticks that also have rudder / rotation axis. Any idea where to buy something similar to what you have?   Anyone? Any idea?

PLEASE, COULD YOU PASS ME THE STL FILES TO PRINT AND TEST YOUR MECHANISM?

Wow you are awsome üòç i always wanted to become a person like you and today, Finally youtube algorithm recommended you. Keep building stuff you are awsome üòâ

Love your channel. I'm new to animatronics, but am learning so much from your videos. I recreated this project but can't seem to get the smoothing code you shared to work. I wrote simple code to control the motors with the joysticks (I have the same equipment you used), and it works fine, but the smoothing code you wrote makes two of my 9g motors go absolutely crazy and it won't move my 55g motors at all. Any tips/thoughts? Thanks again for your content. I train teachers to integrate technology in school and this has been extremely helpful for us.

Hi James,¬† Thanks for this video, it's awesome. It has been massive inspiration for me to have a go at creating some animatronic eyes of my own. Something I've not done before. I have based my design on yours, with a few things done a bit differently, so as not to copy you completely. I like to meddle with RGB LEDs mostly and this is one of the things that differs from your design.  I'm also creating my own video about it and given you due credit. If it is okay with you, I'd like to add in an 8 second or so clip from your video into my own, just to illustrate the origins of my project. I'll also add in links to you of course. Are you okay for me to do that?  Thanks, Steve Manley

can we purchase the 3d printed parts?

Can you send a github link of the code

@ironman5034¬† I have no link, but I do have the code.  if you give me email, I can send code.  Code is in 6808 assembly, but fear not, you can follow the comments & port to any language you want.  Smoothing Code has only a few lines!           I have done what James has done (in assembly), on ONE microcomputer with NO other "shields" or other hardware other than the power supply.  I can generate as many servo signals from that ONE controller as I have port lines.  I generate the PWM signals in software simultaneously with the rate-of-change math.  But you can choose to do them separately.

Link to Github is in the desacription.

@Froggie_vr Were you able to download the files?

@RoboAnders¬† ye

@EmaleesBoyfriend¬† When I click on Download, I don't get a file but a kind of text document opens. do you know what i'm doing wrong

I want to make a super creepy Chuck E Cheese.

Any chance you could give the full cost and time to produce?  I appreciate your solutions to my wondering.  Keep em comin.

James, could you please list a BOM for where to purchase fasteners for your projects. It would be a major help. I printed the model and it's been tricky to figure out.

where are the stl files for printing?

Eyeballs stop very abruptly

Robot: "I Have No Mouth, and I Must Scream"

Great tutorial!  I cannot seem to import the .stp file into Fusion360.  It fails on upload.  Help!

so the answer is an IIR filter, gotta love dsp

You could scale the smoothing time as an input to characterize different "emotions" in your animatronic.  Energetic states would have sharper smoothing and more lethargic states would smooth more slowly.

@james burton Is there a BOM available? I have all the parts printed for assembly and need to get the proper hardware.

fnaf

if you can show me without using a 3d printer then you are a handy harry. But this is just a game!!

why that creature looks like it gonna give some master oogway advice

price in banglades?

You should make the eyes unsmoothed as they were as real eyes dont have any smoothing when they look around, and for the rest, near the end of the deceleration make the value go straight to zero, so it decelerates then stops suddenly when its almost done decelerating. This will replicate human movement quite a bit better. Great Video!

Very Good!

Sooo cool!

What size bearing and self rapping screws did you use?

Cool fnaf in real life

This is great videoüôåüèªüôåüèª is there any video for stepper motors as well?

Did you download the zip of the whole repository?  Several other people have built this already.

That worked!  I was right clicking on the file and saving.  This is amazing.  I am 3D printing all the parts and modifying the fusion file to fit my servos.  I wish I had more information about the breakout board that the servos plug into.  I am still more of a beginner.  Thanks for your help!

I use WD-40 in my code, works smooth af!

Hi thank you for sharing your information and yes I do have a question :-)   In your sequencer sketch,  why do you use 4a and not 6 and in void setup, you have the pin mode a0 a1 a2 a3 a4 a5 what are they for   thanks for all the videos very entertaining !! and informative.

Absolutely impressive

Add random blinking

Learned that trick when programming CNC in the '80s.

This is awesome I've watched a bunch of your videos in the past but for some reason I don't appear to be subbed. I can fix that

does anyone can tell me the angle of rotation of both servos please? Thank you

Excellent vid.  Would have been good at the end to show side by side the same action with smoothing and without smoothing - so as to demonstrate clearly the net effect.

how can you get stl files?

Hello;  How can I convert this file to STL file format? I just use Ultimaker Cura.

Could you share with me the 3d models, electronics, and mechatronics of this robot head please ???

I thought robotics was hard, I do harder stuff in game design all the time. working with vecor3's Quaternions etc, but with much of the same types of maths. In unity, our most common soft transition functions are slerp and lerp.

I recognize this type of smooth equation. What is it called?

If James is clever enough to code in movement dampeners he is probably fully aware that eyes should move with snappy movement. I think rather everything moves with smoothing simply to demonstrate the technique, especially when you consider that this is miles from a fully featured animatronic.

I love these great little how to videos

Similar technique can be used to smooth analog signals, a FIFO buffer of 10 or so values, added together then divided by 10. When a new value enters put the old one out and reaverage. Easiest is to keep an array and cntr. Put the value in at the cntr, increment by on. If the cntr >9 reset to zero. You just overright the last item in.

so the next step would be something like PID control?

this was really very helpful. please please please bring in more tutorials like these about minor things which go unnoticed in a larger project but are key to its success. thank you!!!

James,  You're the Man!!))) ü§ñ I may get another t-shirt))))

Is there a list of the servos, electronics and sources available? It would be a great STEM project for some kids I am tutoring.

All I caught was 9 gram servos for the eyeballs and lids.  Tons of 9gm servos on Amazon.  Pkg of 10 for $20 USD.  But being new to motors, I'd love to know what size the larger servos are?

why this feel alive when it bilnks

This machine feels alive

beautiful!  I'd love to build this for my kids but currently do not have solidworks, fusion or any other decent CAD software, actually. could you possibly share discrete stl files rather then unified STEP, for ease of printing?

This worked great to make my robotic arm project way less jerky!!

Really enjoy your work, sir.  Just subscribed and look forward to watching many more of your videos!  Well done.

That really reminds me of when I was looking into jQuery animation envelopes, ease in, ease out etc. I'd mix and match different envelopes depending on initial velocities so a slow turn would slowly ease in and out, whereas a sharp move would pick a sharply rising envelope and then slowly ease out to target.  Now I'm writing this, I realise, isn't this what makes modern 3d printer speeds possible?

Ohh I see, so you did a leaky integral filter, nice

This is great. Can you describe or show in a video how to control the animatronic using a standard RC controller.? Thanks James

James Bruton: Congratulations. It seems very basic but ... It's very elaborate.

I would love to see this used with a DMX shield and a lighting board to control the motion.  Possible?

really good video im currently printing this mechanism . Can you add in this description the reference of each servo motor ? thank you :)

Thanks for sharing this trick

This actually makes it look less organic, not more.  If you observe things like eyeballs, you'll notice that they don't really move smoothly like that. They jump from one point of focus to the next unless they are tracking something. Certain muscles are fast twitch and are attracted to lightweight appendages with low angular momentum. This results in a much twitchier appendage. The eyes are actually the best example in the body.

The discovery of the PT1

What you have described is a first order filter - works well. Change it to a second order filter and you will avoid the sudden jerks at the start of the movement. Use both and you will get the best of both worlds.

Amazing!

Wonderful work explained how to reach you..

Cool. üëç I think the eyeballs maybe need less smoothing? Eyes tend to "flick" rather than "roam" and quick motion looks a little more "normal", IMO.

This is awesome :-) Where can I find the print files?

So actually, what you did between 5:15 and 5:50 is a digital low pass filter!  Pretty smart indeed!

For the code optimization geeks (like me):   'switch1' only changes when the switch does, yet it's multiplied by 100 and then by 0.05 in every loop. Since that never changes, you could simplify it by just multiplying by 5  (100 * 0.05).  The compiler might even be able to optimize 'switch1 * 100 * 0.05' into 'switch1 * 5'.  I understand it's written that way to show how it's smoothing the values, but an even more efficient way would be a simple conditional in place of most of the calculations:     sw1Smoothedt = switch1Prev * 0.95      if digitalRead(12)  {        switch1Smoothed += 5   }     switch1Prev = switch1Smoothed

Thanks! Lovely demo and very well explained. Such great results too! =D

Gotta love the advert I got on this: James: "Here are some super cheap random name servos" Advert: "Do you want to make quality metal parts with MarkForged?" XD

it's more satisfying at the speed of 1.75x

Wow... Wow Man!!! Amazing. Just Amazing. Thanks !

I wish my human could build robotics that well... I'd have a body by now.

1M üòé

Are Stl files available?  Where?

where can I find the stl files you used to print the mechanism?

Is ist posible to geht the stl ? I can not work with the stp üôà

I would love to see Product links and a bit more detail in the GitHub readme. Along with possibly individual stl or stp files.  It would help with replicating the project. The product links, just so we have an idea on known working hardware. and the splitting of the files, because it takes quite a while to split out individual components and convert them prior to slicing.

You don't need `switch1Prev` because it always has the same value as `switch1Smoothed. Just `smoothed = smoothed * 0.95 + input * 0.05` is enough.  It's also worth noting that eyeballs are the fastest-moving part of the human body and naturally have motion very similar to servos. I would not smooth them, or only very slightly, but have them target something in global space with inverse kinematics, and have the head follow the direction of the eyes slowly and smoothly.

Nice

This is amazing!!!!! I never thought something like this for ‚Äúany one‚Äù can do. Very helpful!! Thank you.

That is Amazing!

VarSpeedServo library. Easy peasy

May I ask where can I find those joysticks to print? my boy will love this! :D

Very cool! I still think the blinking and eye movement look a little inorganic however. The blinking is unnaturally slow (limited by servo?) and for most living things, the eye movement takes place while the eyelid is shut. Having the eyes move side to side with the eyelids fully open looks too robotic imo. A quick blink followed by quick eye movements while the eyelids are closed would look much better. I realize you are probably limited on the servos but it'd be interesting to see how this could be improved.

I have an old rotary dial phone. You can‚Äôt use it any more because everything is digital. Would be awesome if you could emulate the phone central and make it IP connected. You then dial the IP address of one with the same code running and can speak together. It should of course both support the waiting for number tone, ringing tone, invalid number (can‚Äôt connect to ip), no answer and hung up tones as well.

This is incredible.

From the link in the video description

@jamesbruton¬† Thanks james ,you are the best, i m currently a student, will surely be a patreon one day when i get a job, for now i watch all ads on ur videos without skipping, u r writing history, again thanks a ton, loads of love & respect ‚ò∫Ô∏èüíêüíêüíêüôè

@jamesbruton¬† Thank you Mr. Bruton, but I am new to all of this.  I clicked where I could and did not find any .stl files to print.  I know you are a genius but if you can dumb it down further for me I would appreciate it.

The stp will load into any CAD software

People may also want to research tweening, Hermite-step, Ease and Fade equations üëç

wow

2 mid advertisment and 2 Sponsor in the video starts to be annoying, even if i enjoy the content

@ James Bruton Can you please tell us which software do you use to design the mechanics and the body of your projects?

Nice video

Great tutorial. Might you be able to show how the device works without the smoothing code so we can get a comparison?

The motion looks fantastic!  The eyes should be jerky although.  Eyes on real creatures lock on to a specific point very rapidly.

Looks cool! Cartoonish , but I can guess that cartoon was reference, but not real life person

Wow, great Halloween project Thanks for sharing your experiences with all of us :-)

Stop talking weird

like Domo

Tried this technique with different servos. The end effect depends heavily on the load and random quality of the servo itself. Usually they struggle and jitter with small changes in position.

4:34 to skip most of the repetitive 3D printing.

üò∑ü§ñ‡¥Ø‡¥®‡µç‡¥§‡µç‡¥∞‡¥ÇüóëÔ∏è

This can also be done in analog for other actuators using RC or LC filter circuits.

Nice project. In the standard Arduino IDE examples, under "Analog", we have an example called "smoothing" which basically uses an Array of values in order to get an average value which smooths over time. I use something similar to send smoothed out values over OSC/MIDI

Can we please have a 1 hour loop of 8:10

A good eye rotation calculation has each eye looking at the same point. Then you get a bit of toe in. Then you can move the virtual look at position with your controller ( could be on an arc) This looks more realistic than both eyes in parallel turning at the same speed.  Nice work. Good building and showing how to use a simple low pass filter.

I hadn't watched a Bruton video in 4 years and it's quite striking how the narration has changed. It's almost like there is smoothing on the end of sentences. :)

I think it would be cool to see this where the eyeballs themselves don't have this smoothing as eyes tend to "dart" as they're moving.

Patrons and Channel Members get the ad free version a week early!  All this content has to be paid for somehow!

It will be awesome, if you will make eyeballs move discretly and also add to "neck muscules" some low frequency shake!

Nice idea.  What about sensors to detect distance to object?  Then you could have it go cross-eyed as you brought objects close.

I think I figured it out, it's a conscious effort to talk more slowly, probably as the result of feedback.  My solution. Watch the video at 1.5 X and I get the faster talking Bruton back. ;-)

Uncanny. Out of interest, I've been working on a robot arm stroke 3D printer in very early stages so far and I've tried to write some basic interpolation code in python (as a prototype) to make sure the arm moves in straight lines (if for instance it has to move along a diagonal and the X axis movement is less than the Y axis so it gets where it's supposed to be in the X axis first then sharply changes direction to move in the Y axis) but it's kinda messy and the way I set it up I find hard to actually get my head around when I'm feeding it data because of the way I set up the inputs, would this or something similar work for that kind of use case or is it just cosmetic for things that need to look nice.

the robot moves so smooth that it looks like it was animated by pixar.

Superb !

This robot terrifies me.  Too much Fnaf I guess  ;w;

Nice one, this could be done with fixed point arithmetic instead of floating point in order to save precious cpu time.

looks like a blue Pepe the Frog, just saying if you put some foam latex rubber on it you might be able to get some uncanny valley memes out of it. becoming a meme if you are a youtuber is likely a profitable thing.

In animation, this type of movement smoothing is called easing. I don't know the math behind easing, but your video explained the idea nicely!

You can re-arrange your smoothing formula a bit.  newpos = oldpos + k*(target-oldpos) where 'k' is typically 0.05 to 0.03.  This is a tiny bit faster (only one multiplication vs two).  But more importantly, needs only one constant.  Your original formula (@ 6:11) you have to always make sure that the two constants (0.95 and 0.05 for example) add up to exactly 1.000.  This can be easily missed when tuning the values.  Also, you can get a bit more precise by using the delta-time step in the formula (but takes another mulitplication)  newpos = oldpos + k2*time-step*(target-oldpos).  (where k2 is a new constant tuned for)  So long as the delta-time isn't very long, this can give very precise movement that accounts for just how often the loop runs.  For an animation it's probably not worth it, but if you're doing precise positioning of an item, it can be useful.

Cant find the print file Sir... ü§î

Hi James, thank you for sharing my project! I am not using arduino this time, but your suggestion to move it smoothly is great! I will adapt it in future movement sequences. Right now I am focused on the hardware. Files are being shared, so anyone can build it üòä

This video will cause you to enter manual blinking mode.

Awesome! I was thinking of doing something similar with LEDs... But the project kinds of faded... This is an awesome kickstarter for me :). And the multitasking links! Thank you so much! Just what I needed  :D

Maybe adjust the eyelid speed to be snappy. Usually eyelids aren't so slow. Otherwise it looks like it's been smoking weed.

Always enjoy your videos. Project suggestion: A mini motion platform for a desk chair / flight sim.

Record a video of yourself and replicate. Must get across the uncanny valley

You should make a rubik's cube!

wall-e momen

That smoothing algorithm you used was as elegant as it was ingenious.  And the way you demonstrated this in the visual graphing really made this apparent you went from those choppy square waves to those poetic looking curves.  You should consider making a full-sized animatronic running 6 - 8 arudinos to show how life like this can be in terms of arm/hand movement,  treadle turning, and of course facial movements including your pair of amazing eyes.

how would this work with the jetson nano PCB to test the io pins response time.. then going to some usb-camera opencv code...?  thanks a lot, very interesting...:)

This is definitely a great tip for digital reads, but I feel like it goes against most analog read applications. A performer operating an animatronic live will almost certainly want their  performance closer to a 1-to-1 movement. That's kinduv the whole point of reading the analog values and moving according to those values, so that the performance of the human comes through. Adding a hard and fast, always on smoothing interferes with that performance by reinterpreting the puppeteers movements. Again, that's not to say it doesn't have its uses, just that adding it to joystick or potentiometer inputs feels counterintuitive.

I'm definitely going to try this! Thank you James!

This is so awesome!! Gotta try this with one of my up and coming projects!!

Eyes dont decelerate though, they fix on objects they are looking at. the more '''organic''' method would be controlling the eyeballs to point at what the head is moving towards before the head gets there, and fix the 'look' on that object as the head finishes the movement. I bet you can calculate that without feedback to the eyes.

While I don't really have anything for you at this time, I'm thinking it would be fun if one could more or less easily modify the standard programming of off the shelf toys.  I'd like to see a fairly universal module one could stick into an Elmo or any of the many other similar toys. It would be wireless, of course.  Forward, ever. :)

One thing I would be interested in would be how can you achieve to make the eyes look after you if they sense your presence in the room (if you go tho the left, they will look to the left, if you go to the right, they will look to the right) I am currently trying to do this with 2 ultrasonic sensors, but they are not very precise and the area in which they can detect motion is very tight. What other ways would be to achieve this without using some fancy camera detection? :)

this looks like the turtle master from kung fu panda, make it say, id like to hear it say "my time has come"

this kind of multi tasking can also benefit from setting up a timer with interrupt and check flags/update values that way. Less overhead than checking millis() all the time if you need to do more heavy lifting in your mainline code

For anyone wondering how to smooth the launch of the curve as well, just check out different interpolation functions.  Trigonometric or cosine interpolation is a really common one for essentially making this curve from the video smooth on both launch and landing.  They are also going to be just one line in your code!

Spectacular

Nice video! Pretty much showing how easy it is to do essentially just a kalman filter. Changing the percentage you rely on the previous and the next value would be the Q and R in the filter

What software did you use for the head.stp file ? Would you post the .stl files for those parts. Thanks

where is the before verses after smoothing footage? or side by side comparison

I loved that video! Well done! My suggestion for a future video would be a beginner‚Äôs guide tu Fusion electronics. Design a simple PCB and and have it made by JLC PCB!  Fusion electronics really opened up so many possibilities for me.

Brilliant, straight-forward, and simple to implement! Thanks James!

cool, needs a random fast blink function

I love seeing the effect finer control of servos can have on the performance and look of animatronics. Reminds me of a Disney Research video where the sudden stopping of the motor is offset by other motor movements to reduce vibration. https://www.youtube.com/watch?v=Z1jgaEO9aRs

This is actually PT1 behavior, the system's differential equation solved as a discrete difference equation. You can smooth further by adding more coefficients

It's crazy how big of a difference such a small chunk of code makes! Very lifelike. Thanks for sharing!

Soo it's an IIR filter.

You can at least mention PID regulatir (resp PI)  for the people whoom want to educate themselvs little more, but great job at all :)

same!

a small matrix of ir motion sensors should work. Would act as a super low res 2D object sensor, and then just aim up at avg human eye height

Very good point. A programmer friend of mine went and did his high school maths again to remember how to use Sin wave. He uses it to start and stop motion smoothly.

do i see a johnny 5 as a future project????

This is a great video i wish I had this back when I starting building animatronics.

Brilliant üòç

Very cool, but still pretty creepy.

Excellent tutorial!  My own experience with smoothing motion comes from the control used in the Canadarm/Canadarm2 robots.  In those, the operator puts in a desired motion vector, and the joint servos are commanded simultaneously to give a blended (resolved) motion along the desired vector, which changes every 80 milliseconds.  The operator's command is with two joysticks that give 6 axis control.  It looks very smooth and natural (but of course costs multizillion dollars).

\-_-/

make a remote-controlled puppet with this and I'll be satisfied. This is amazing tho

How a simple piece of code makes such a big difference, thanks!

Please put this eyes in your Ultron please please please

Fnaf: Ho? You're aproaching me?

I think you should have the neck controller slightly underdamped. If you turn your head as if to look at something, you tend to do it quickly enough that you overshoot ever so slightly

Just make sure you're not turning purple

James just reinvented TDMA.

You should: A- Not make the eyes change position smoothly, human and animal eyes do move very suddenly, except for when point B: B- when the head moves you should make the eyes counteract the head movements so they keep aiming at one position until you make them change target.

hey, this looks really cool! please look into the "uncanny valley effect" though, before you go too far into this animatronic project.

I would be happy if the eyes could move to the side as well.  Then you can see whether the eyes are looking near or far away.

Great work, thank you for sharing

I did something similar to that smoothing code for an ESC but with integer amount rather than percent.  Percent makes so much more sense!

holy shit

Out of all the animatronic tutorials, this one manages to make arduino coding sensible... what? Awesome üëå

its possible to move your eyes continuously by defocusing altogether

@Blox117¬† Ok.

I think you could make another tutorial diving deeper into PID control based on this same animatronics

Will you be continuing the theme through to full blown animatronic creation? Would be great to see mouth development with lip sync etc...   Great video as always üëç

So cool, I'd like to learn arduino running several routines at once sort of suedo dual processing, like establishing priority, and if  a routine has been finished, have a little coding experience, but not to the stage I could write firmware for a 3d printer on a arduino üòÖ

This method also works well for making LED animation look smoother.

What about the eyeballs looking down and up?

This is absolutely superb!

It's got that Sleep Eyes effect that we see with Snuffleupagus. üëÄ üåõ

Thank you needed this so much

I Like your project I want to make one. Where are the stl filed?

funfunfun!!!

Or you could have used the same PID as many other projects.

Sense the servo needs some time to accelerate, I think what you get in the end is mechanical acceleration and electrical deceleration combined

Absolutely love this video! This is so well presented and easy to replicate at home, great content man ü§òüèΩ

It is fascinating. Suddenly a thing have eyes, it appears alive. spooky ;) Thank you for this tutorial!

Amazing as always. I really want to make this. The smoothing makes it look so cool.

First order filters are such a huge asset for all digital control systems

Show how to zap it with lighten to make it come alive.

Yay üëç

This calls for a follow up where you put cameras inside the eyes and you use a convolutional neural network to make it detect things and then it will randomly stare from one thing to another turning the head as it centers the object in it's view. ... And if it detects a human it will always look at the human.

That structure would be interesting to add some mems sensors control with PID.

Example?

This is Mike, you don't ask him for example. His channel is example

I can‚Äôt imagine this. Any examples?

It also works for making smoother music synthesizer sounds

@BlondieSL¬† Hey, thanks - it‚Äôs kind of out of left-field, but your description of the echo problem may have solved a weird problem my plant has been having with an identical pair of Endress-Houser level sensors being used to measure water levels in two identical stainless-steel mix tanks. Visually, the water exhibits no turbulence as the tank is filled, then emptied, yet the graphs from both instruments show regular ‚Äústeps‚Äù as the water level is slowly drawn down. I‚Äôm willing to bet we have a resonance issue in the cavity formed by the stainless tanks, and the interactions with the sonar! Further backing this possibility is that another identical E.H. level does not produce ‚Äústepped‚Äù graphs at all; just a smooth, linear ‚Äúsawtooth‚Äù as the hopper empties between refills. But this isn‚Äôt water, it‚Äôs soda-ash, which I‚Äôll bet dampens the hell out of echoes compared to water. Thanks for possibly solving a real head-scratcher!

It also makes a onahole hole moves smoother

Geez people. If you need to ask him for an example what you really need is an introductory course on Arduino PWM programming. Think of a servo as a PWM -controllable device. Nuff said.

@yt45204¬† That's excellent advice, so I went out and double-checked, but the outputs were verified to present 14 bits, and identical units measuring dry powder (soda ash) exhibit none of these symptoms. When the vessels fill, they fill much faster (~5 minutes) than when their batch is being drawn down (~4-6 hours), but the fill trend is as smooth and linear as could be expected.

@mbunds¬† Hmmm...  Would it be possible to add a stainless-steel mesh inside the container to interfere with echoes or even just attach heavy concrete blocks (or w/e) to the containers to dampen vibration?

@KeithOlson¬† You may be on to something, but our level sensors use microwaves, so damping with a (grounded) mesh is actually a very good idea! When the fluid level falls enough to cause "resonant peaks", grounded stainless-steel pads made of several layers of mesh may be able to disrupt the spurious "echoes", and reduce the false "stair-stepping" we see in the signal.

Can't you use the derivative to calculate (and limit) the inertia independent of the loop? That would make it easy to calculate based on the current time.

Perfect timing, I'm just about done with the physical design of my omniwheel astromech project, this will help a lot in the movement code.

Progressing the video, the robot gets more and more creepy over time

now you have to make an smaller ELMO version ......Please üëçfor yeeees andüëéfor noooo

Really interesting that just a order 2 FIR filter, has such an affect.  I wonder what would happen on higher order one.  simple, great.

Great project!

It would be interesting to see how the eyes moved if you opted to remove the black eyes, put cameras in their place and tried 3D plans & AI projects with the eyes.

great

wow this is beautifull

Nice video, thanks :)

I want to see this guy build an animatronic like the one at pandora. He‚Äôs got the skills to make it really realistic

Que maravilla ‚ò∫Ô∏è. Muchas gracias por compartir .

he's the man behind the slaughter

Hey James, It's always interesting to see you make these simple hinging parts. I'm wondering why you used a normal bolt at 1:15, while for the next one (1:32) you seemed to have used a self-tapping screw. Also, how do you like to make the thread in your 3d printed parts? threaded inserts or just threading the 3d-printed hole?

This is great but I'd love to not only be able to do animatronic motion recording but how sync it to audio. I've yet to see a good example on how to do this using an Arduino. I've had to do it using Visual Show Automation (which also can do video) alongside a pololu micro maestro board.

You are so fast with Projects, really inspiring

I need walking legs for a T-rex can you make them

kind of cool but you could as well add a small drift to the values so it will go past it's point of stop and slowing back to the location it was set to go.

D√≠ky!

You should try RTOS systems for multi-tasking event. It's more reliable than checking the clock. Here a YTB tutorial with a ESP32 board (cheaper as an arduino, and much faster) :  https://www.youtube.com/playlist?list=PLEBQazB0HUyQ4hAPU1cJED6t3DU0h34bz

U only need nuts or threaded inserts if it needs to be really solid and withstand a lot of stress lol

I watch all your videos and this was the first one where I was like... man this would be awesome to do with my son.   Except I don't have a 3D printer.  Wonder how much this would cost to get into.   I am a computer programmer so thats not a problem and I'd love to challenge myself to learn to solder, I just don't know anything about 3d filament and costs,  and don't wanna be 300 dollars + into a project when i realize it costs $100 to print alone.    Great video! thanks so much!

Quite elaborated video just to explain a low pass filter... But well done!!

Congrats on reaching 1m subs. I‚Äôve only just noticed. üèÜ   Thoroughly well deserved. Been watching you for years. You‚Äôve taught me a lot. Even though I‚Äôve been programming since 89 and the programming isn‚Äôt too advanced for me, it‚Äôs a brilliant intro for my daughter and others.   Thanks üôè

Great video as always. Thanks. üôè  I know this wasn‚Äôt the point of your video, and you will have obviously thought of this, but the eyelids would be better moving much more quickly. Easy to add a second set of methods, or add a parameter to select the required smoothing factor etc  More videos like this James üëç

So that‚Äôs the P in PID, so what about also including the I & D?

What's the relationship between the fraction used for the filter and the actual time-constant ?

Do you even sleep? O_O

Congrats on 1mil subs! idk how long its been since u got to it but congrats anyways! Idk when I followed because I made this channel more recently, but I remember back when you made the xenomorph, this channel is what got me interested in engineering, arduino, and 3d printing.

lerp and slerp

This is Proportional control. ie. the P part of a PID controller.  Good work.

Only the eyes are now the opposite of reallife. Even if you try you can't move your eyes smoothly

I would love to see your design for a talking skull using Arduino.  The servo mount design would be really awesome to see as well. All of the servos would have to stay in the skull, keep it as a 3 axis design, there are some files on thingiverse but they aren‚Äôt great.

nicely done. Now im wondering about putting cameras in the eyes and having AI track human targets with the eyes. :D

have the eyes follow motion activated or follow an object

I was literally doing the same thing to my code last night. Great minds think alike :D To ditch delays I usually do if(millis() % 1000 == 0){//do something here every second}

...and then I printed shoulders, 2 arms, torso, hips and 2 legs using additional 78 cheap servos I got from amazon so I could effectively demonstrate 2 lines of code...

In the animatronic world this is called compliance. Disney Reaserch has been doing a lot with algorithms to make robotic movements match what the animation simulation says they should be.

great job

Really great video. Interesting, usefull and entertainment too!

Thanks I hate it!

you could check out your local makerspaces if they have 3d printers on which you could print your files. printing isn't expensive, neither is the 3d filament. a good 3d printer to start is the Prusa Mini (least hassle for a beginner) or Creality Ender. i think with about $500 you are good to go for quite some time

These are completely 3D Printed: https://youtu.be/mcuB56janQw

Simple and beautiful

this guy makes a whole ass senior engineering project every week That‚Äôs dedication

Getting back to basics time to time is really important Thanks and once again great job

I prefer the slightly simpler expression:  switch1smoothed += (switch1 - switch1smoothed) / 20;   It gives exactly the same result but you only need to specify one constant. A modern compiler should optimise / 20 to * 0.05.

Super cute

Brilliant.. I need to try this out

This was very informative make more videos like this üî•

hey if you ever read this i thought of something that would make this a really cool desk toy mount a camera between the eyes to track a laser pointer

Could you please make a video showing how to fix this common problem with servos?  If your servo driven robot gets turned off randomly, the servos will quickly jump to the start position next time it‚Äôs turned on, which can damage the robot or the servos.  How do you make your servos go to start position slowly and smoothly?

I love these bite sized tutorials!

Get a Pi todo facial recognition and send serial commands to replicate someone facial features and head orientation.

Great video!  Thanks.  Would love to have the servos move to sound/music input.  Love that series of adafruit posts. I've read it multiple times to grok state machines.  They have a new one that is circuitpython based.

At the end I was looking at your bender head and was thinking that you could put this project inside it

That method of smoothing is effectively what happens when a capacitor charges/discharges in a DC circuit!

I know that you build most of your projects using Servos, but could you make a video about stepper motors and how to control them with Arduino? ex. Controlling multiple stepper motors, Acceleration, etc.

sweet, now tie that into a face tracking AI and let it control it's own movement.

This is so simple but looks so cool. I love it.

He inspired by tesla robot

So cool.  Animatronic grogu? :D  One thing is say, is it might be useful to have a second were input that is quicker. Eyes can move very quickly, so it looks natural for a character just casually looking around, but sometime to convey some emotions it would be helpful to have fast darting eye movement.

This NEEDS to be turned into a Halloween prop!

How did this british accented guy educate hƒ±mself?  That s What i really Wonder.

Amazing result this week.

@caner8688¬† I‚Äôm sensing some sort of antagonistic energy here, just wondering

@planetdesign4681¬† well after a mature age if you didnt get, smoothness in action becomes "divine" secret.you watch and see the speed and perfectness in productivity at the same time.

We do have some excellent universities in Britain:Cambridge, Oxford, Hull,‚Ä¶. But this hands on stuff wouldn‚Äôt be acquired there, this is pure passion and practical graft

@SamWane¬† One observation I have observed about the British is that they value education.  (The web shows so much of this!  it seems there are so many excellent education British videos.  Examples are Numberphile, Nottingham University's "elemental videos". etc.)  In the USA, what is valued is SPORTS,  not education.

Change the 20 to 16 to make the divide a bit shift. Optimize that, compilers! Away with the evil bloating point math!

@6alecapristrudel¬† Yes I use powers of 2 when using ints so it can be done by a shift but do floating point units or libraries optimise power of 2 to just exponent changes?

@nophead¬† No idea, but good point! Could be good for doing floats on an 8bit micro. Dedicated hardware likely does any multiply in a single cycle.

Or spoken text?  You could have bedtime story reading mode, where eyes flick right to left quickly, and then left to right more slowly.

I never thought about this. Ive made janky animatronics out of cheap servos and ping pong ball eyes, I like your eyelid solution of having 1 servo work both lids, took notes on that one. Interested to see how you would do eyes that move omni-directionally. left right , up down. (I had a vertical servo and a horizonal servo attached with zip ties so they moved with some flex which helped smooth the movement a little. But tiny little screws being the pivot points in pingpong balls only lasts so long!)

If you‚Äôre looking for video suggestions, how about a deep dive into the code required to slave a motor or servo to an IMU? (Self balancing robot e.g.) I know you‚Äôve used it in many of your videos but would be nice to have a one stop shop video on this programming technique. Would be very useful to your viewers. Ciao.

That‚Äôs cute! I use a RC radio for setup and servo controller with VSA software, https://youtu.be/iBjSAV9FoO8

Another way is the single pole digital filer.    Vnew=(Vin-Vold)*delT/tau+Vold Vold=Vnew  Tau is the time constant (small is fast) and delT is the step size (in your case 10ms).  Vin is the signal from the switch.  Vnew goes to your servo.    Good video as usual!

James, please show in your videos more footage of programing process of your projectsüôè

Great job! But this still looks pretty DEEP in the uncanny valley. Animators are struggling with this for decades, two lines of smoothing wont cut it. But its a great start.

Thanks for making this video. I'm going to try using it to smooth out Bittle's movements.

Oh man, this is so damn helpful. Thanks James!

One thing that always gives these things away is that the eyes don't track to their environment. In real people, you always focus on something, and your eyes stay locked toward it regardless of how the rest of you moves, with only tiny movements shifting the pupil about to better focus, if there was a way to track random points in the room, that would probably do a lot for realism!

Fnaf

It'd be interesting to see if you could set a "per servo" smoothing, since some things like eye have a lot snappier motion.

Very interesting- I really appreciate you sharing this practical example.  I‚Äôm inspired üëçüëç

What is an elegant way to do smooth starts?

How did you print the eyeball in two colors?

Beutiful project! Also I don't mean to sound rude but I feel like your videos would get mor attention if your thumbnails just had a normal background to it

Shameless plug for the NoDelay Arduino Library lol

All that effort to demonstrate 2 lines of code. Way to go above and beyond to teach people James! Also how did you come up with that idea?

I use the Timer function when I need repetitive code to run on an interval.

If the eyes were a bit more twitchy it would look more realistic. Maybe set the smoothing to 75

Great stuff. Thank you.

Yes, actual human (or animal) motions are different: globally, they minimize acceleration (more specifically: muscle power) while getting to the target as quickly as possible.  This means your motion would consist of two smoothly connected quadratic parts.

They have I suppose? The values set for the smoothing is same for all section. Just guessing here don't be mad

Well done, really helps!

idk why you rendered this video out at 50Hz. Just a heads up. 60Hz is better and more standard these days.

I think the code would be easier if you used millis and the multitasking stuff on the smoothing code and used delays on the motion loop.  But, sure, the best would be to get rid of all delays!  Also, I think you would benefit a lot with a video making improvements to speed up your printers, with Klipper for example. I'm sure you expend lots of hours printing everything.

Hey James, what do you think of the tesla bot?! Or what we know of it?

Interesting Why Not use the Library called SmoothServo, Would this not do the same thing?

brilliant, thanks!

10:18 omg that code is so inefficient.

Smooth motion is nice and all but that's actually not how eyeballs work. You've actually made them less realistic.

Fun fact: a similar method can also be used to fuse two sensors' data giving out the same information to smooth out the output data, for example:  If we have an a gyroscope and an accelerometer sensing the same angle, we can set a new variable fused_angle = 0.95*gyro_angle + 0.05*accel_angle.   Cool thing about this is that the gyroscope captures changes in the angle faster but it has what is called "drift" (the value it senses slowly deviates from the actual angle), while the accelerometer is not nearly as fast at detecting such angle changes but it does not drift. Fusing them together gives you an angle reading which is responsive thanks to the gyro contribution, but does not drift thanks to the accelerometer cobtribution.  This is a good alternative to using more complicated (and computationally expensive) methods such as a kalman filter while still giving very good results in most cases (at least when talking about arduino projects).

This is cool.  It's also another chance to let everyone know that Disney has a lot of research on this.  Their robots are a lot heavier, and if you just target a location, the whole robot can rattle around.  IIRC, they used some kind of overshoot method, which allows them to move fast, yet keep the robot from shaking from the move.  I think lol.

I really like your little eyeballs and eyelids a LOT more than that first human head you showed!!! I would love to see some of these kinds of things integrated into open dog where the visual sensor for depth would be able to pan and tilt in the same way but in a sort of mechanized organic kinda way like this!

One of the best in robotics. I am a huge fan of your work. Please can I request you to create a video that can help people learn about SCARA robot.

In animation everything should have an ease in when it starts moving and an ease out when it stops moving. The easing should depend on the total movement, the speed, the elasticity, the mass, and things like that. Something with little mass can accelerate quick and it can also decelerate quickly. So the eyelids don't need as much smoothing as the eyes, and the eyes don't need as much as the head.  I think the way you did it is a huge improvement on the default binary speed. It's also nice that it is very easy on resources and it's easy to understand and implement. So I think this solution is a very good compromise between realistic movement and complexity. This also makes it great for beginners.  That said, as I mentioned in the beginning of my comment it should look even more realistic if it also included an ease in. It should also look more realistic if all servos get their own smoothing parameters. Choosing the wrong smoothing can make it look worse though, so it requires a bit of tweaking

Super useful video, thank you for that! The robot projects on this channel combined with some animatronics like these could become terrifyingly characteristic

That's going to give me freaking nightmares!!!!

Wow just the help I need!

that would look really cool if you instal on your bender in the back ... and really interesting im going to give a try for sure!

Slim Cognito!? Is that you?

C is for cookie...

You probably did this already, but I want to know the nitty gritty details about building a balancing robot (coding) cheers love your work

Of course, I read this now, months after giving up on trying to work this out on my own on 6050s, and instead just (through sheer luck) used someone else's head tracker XD  All jokes aside, this is fantastic to read and I might give it another go. While the tracker I found works, it'd be nice to do some customising!

Yes. This is a good option. For anyone who wants to learn more, the sensor fusion version described here is known as a Complementary Filter.

@martinmckee5333¬† thanks, completely forgot about the name!

Wow...  This is the kind of thing you don't know how to find when you need it, you don't learn in a class because you were distracted for the 2 minutes it was mentioned, and no one talks about.  It's so obvious but so passable.  Great tip!

@fiveoneecho¬† i've been like, toe deep or ankle deep in this stuff for a couple days, and while complementary filters are cool, kalman filters, madgwick filters, and others are even cooler.  (EDIT: wow i missed that kalman filters were already mentioned as more expensive, reading comprehension fail. >_>)  I'm currently using a library called dcmimu (which is the rust port of a c library with an associated paper called dcm-imu) and, frankly, i'm just treating it like a black box. probably shouldn't be, but i haven't had the bandwidth to try to properly evaluate all the options i have, when i'm still trying to figure out what the best method for calibration is. (after all, garbage in, garbage out)

@kitlith¬† Sincerely, I feel like as long as you trust the library, vaguely understanding the concept behind it is enough for most purposes. This approach also lets you quickly assess multiple possible solutions, compare them and decide accordingly what suits you best. I don't see any problem in using stuff as a black box :)

@kitlith¬† I‚Äôve been trying to find every excuse to both use complex filters and avoid complex filters lol

what about if you are too poor to have either a gyro or accelerometer

@Blox117¬†well, obviously then you cannot fuse data because you don't have more than one datasource. I would choose the accelerometer bc while slower  it will nlt drift. Anyway, most IMUs are a combination of accelerometer, gyro and magnetometer and they can be quite cheap, so the scenario is truly hipothetical.

@carlesmolins3269¬† what if you are too poor to have any of them

A little ease in is achieved naturally by the limited force the servo has to move the mass. It would be cool to wire the feedback potentiometer of the servo to the arduino to see the real position. We only saw the desired position on that plot

‚Äã¬†@viniciusfriasaleite8016¬† also the fact that he's converting rotational motion to linear theres some sinusoidal ease-in and out

Can u make a robot like cozmo or vector

Wonderful content thanks any interest in autonomous drones with facial recognition

good job

Hi there James. I built something similar but used oled screens for the eyes. I recall it's called uncanny eyes. I built these into a 3d printed pumpkin for Halloween a couple of years back. It's amazing what a 3d printer adds to Arduino. I love your videos üëç

That‚Äôs awesome! Could you please do a sequel and add a mouth? üòÑ

Now put a camera in the eyes and and a facial recognition algorithm connected to a speaker to say hello when ever you step infront of it.

Great video

This is just so cool, and  useful for me thank you so much.

hey make it automate and react to sound so it would look hunted

That smoothing looks like a RC (resistor condensator) discharge, you could make it delay independant using an exponential

More tutorials!

This looks freaking awesome.

I love your channel! I have a 3D printer and would love to try out some of your projects but I am not good with electronics, and most of them requires parts that seemed to be costly with no practical use if you are not into robotics. Maybe you could share how to make some smart IOT devices using raspberry or even better using arduino as it is cheaper. Something like a smart self cleaning robo cat litter would benefit a lot of people, which usually cost hundreds of dollars.

Building your immortal form James? ;)

Michael Reeves is having a seizure over herw

Please more tutorials, you make them so enjoyable

Fantastic video!  Thanks for doing simpler videos covering the "basics" once in awhile - it inspires newbies like myself to give it a try with my kids!

Mount it on the really useful robot

I'd love to see a video about inverse kinematics. You could make a simple robot arm or something. Inverse kinematics has always interested me.

Good day sir... I wanna ask  I dan a project (motorcycle) to control servo based on engine rpm (@ certain rpm move,  certain degree, etc)( in short: yamaha ypvs or honda rcvalve) think to use arduino uno/nano and a servo  1. Is it ok to run direct 12 v to arduino? 2. What program do i need to learn? 3. Can arduino count direct pulse from engine pulser?  (I've reserach and it seem not so accurate (miss @1000 rpm ))  Thank you very much

That's because it is a discrete first order transfer function just like RC

thanks!

I did that already: https://youtu.be/IN8tjTk8ExI  !!

Yes i would love more of this type of video.. with arduino code projects .

That's pretty cool and so simple! I've got a project I'll be using this in right away.

Excellent project ... looking forward to seeing the head added into the closing montage perhaps with a knowing wink?

Thank you so much. I kinda gave up on a project because I couldn‚Äôt figure out servo smoothing. Now I can get back into it

Now you need a giant paperclip and wala, you have Clippit!

Nice one. Be careful not to add too much smoothing to the eyes though. A lot of 3d artists get this wrong when animating. Human eyes look very creepy when they move too smoothly.

Can you do anything whit leds

Its great to see you using my 5% 95% smoothing algo. You have done really well with this project. Don't under estimate the value of some animated eyebrows. They are really easy to make.

Great video James. Going to implement this on a small robotic arm to stop it jolting when it moves

Smashing video. What your are doing here is the same as ease in and ease out in animation, it would probably be good to look in to animation techniques for animatronics, as all these techniques have been worked out in animation getting on for 100 years ago, the animat part of animatronics is from animation I guess?

Awesome

The ideal behaviour for natural eyes is to lock onto a target nearly instantly and track that target.

Yes, I'd love more arduino videos

Excellent tutorial, well done !!!

Theses little tutorials are a great idea, more please.....cheers.

Another way to do this is to have a second variable called "speed" (or acceleration). Which you adjust positive or negative based on how far the new value is away from the previous and you can then also make the speed value smoothed. Which will make a smooth start + end possible. Now the start is still 'sudden'.

i ran into a similar problem but that was regarding the speakers making a single sound where i needed a dec sound with passage of time, i played around with math functions like e^-(time constant)

Cool üëç

Dang, for such a simple implementation it looks very life like

Thank you great video

Its difficult to move your eyes slowly without tracking a moving object, but you can do it if you force your eyes to defocus or otherwise not lock on to any targets. I like doing strange things that somewhat give people the heebie-jeebies, like moving my scalp without touching it, or making my eyes roam about, or moving in a robotic fashion, or changing my gait to a different one a dozen times in as many minutes, or speaking like a DECTalk machine although that last one is more funny instead XD

Yeah I was thinking this too, eyes and eyelids are probably the worst candidates to show off this smoothing

Agree, totally. Eyeballs move almost discretly in real life

@user-wz3ci8lc7c¬† Yep! I believe we can also say its why most people have trouble when it comes to not looking at things that happen around them, or things that move, its because the eyes move so fast and naturally the brain wants to snap focus on objects. Like men looking at dat bounce, be it an old pristine Cadillac or something finer and fairer XD

See also: Sauron‚Äôs eye in LOTR movies ;-)

That is probably because the muscle force to eye mass ratio is VERY high.  I suggest in another comment that the acceleration value for each mechanism should be based on both the object's real-world mass and maximum available force to move it.  Heads would then naturally move MUCH slower than eyes as can be confirmed.  (You can try to move your head as fast as you can move your eyes, but a visit to a chiropractor will end up being necessary.)

Exacly what I thought. The eyes normally move very fast from one fixation point to another ("saccadic movements"). A different thing would be when fixating at a moving object or if moving at a fixed object while slowly turning your head. The eyes would rotate slowly to keep the object centered.

Hello how are you? Do you have any suggestions of how to make the eyes look natural if you're making a lifelike robot? Is there any kind of jelly or gel like I something that looks natural like ours

As a past animator I did this and I want to get back into animating just to prevent myself from doing it again lol

@Lovekarunai¬†make them move quick. Eye movements are quick. Observe a video or something of someone‚Äôs eye and use that as reference.

Came here to say this, animator as well

It's not just that eyes move quickly, it's that they normally don't move at all when the eyelids are open. That's because, whenever you do a saccade (rapid eye movement), your vision would be a bit blurry, so your brain takes that opportunity to blink (so it doesn't have to blink again for a while, and gets the best vision possible).

It eyes can snap to a position as well as move smoothly.

bro solved the Uncanny Valley     (this was a joke)

Nothing would stop you setting up an individual scale for each moving part. That would make it even more realistic again.

@Lovekarunai¬†  the issue with animatronics like this also seems to be jerky motion thats unintended. due to a bunch of different factors, slop in the mechanisms, friction causing the movement to bind up and stick and so change speed and not be smooth. Plus because of the way the servos are moving they create movements throughout the whole head rig and make it wobble around in a way human heads don't move. On top of that designs that use the arcing motion of a servo arm being translated down another set of arms meaning a sin wave of movement is being used to try to create a linear motion and the result is the opposite of what is created here, the extremes of the servo arm cause very quick movements of the eyes, so a form of what he has done here would work, you want to make the code account for the fact the servo arm motion isnt linear. here hes smoothed out too much and you can see its gone to far in the opposite direction, the deceleration isn't accounting for the servo arm its just a way too high constant rate of deceleration every time, which also looks un-natural. we don't move any part of our body like that. We vary the rate of deceleration a lot when we move, and the deceleration is being applied to the start and end of every motion, not being applied based on what position the servo arm is in to account for its non linear motion.   So we need a code that takes the servo positions and takes a movement command and converts both those pieces of information into the required servo motion to create a near constant speed across the movement.  And then we need designs that prevent any other unintended motions. If you look at the examples at the start of the video the grogu one shows the problem pretty clearly. when he moves his whole head the whole body wobbles back and forth, real living animals dont wobble like that. we stabilise ourselves. So like those robots that balance on one wheel to get really accurate robotic motion we need sensors to give feedback that allows these wobbles to be counteracted by the rest of the "Body".

like Polar Express?! lol!

I think James just smoothed out the internet!

Just use a PID, you'll get all the variables you need

Awasome üî•‚ù£Ô∏è, imagine u connect that with alexa or google homeüòçüëç

Thinking that the useful robot needs some personality.

You Definitely have to make it look at you and follow you and make it look at other objects

This is cool

Is there no dark mode on arduino?

that robot looks high af at some moments (8:40 for example)

Fnaf is here

Epic! I've wanted to do something like this

Can you do save and replay to this  That will awsome

Thank you so much! I‚Äôm working on a 6 DOF robotic arm and want to use various accelerometers spaced over the arm to work out the position of the head in relation to the base of the arm. This smoothing will be key to make the movement of the arm easier to control with less jerking.

That is beautiful in its simplicity, execution and aesthetic.  Well done, sir!

Is there a video and a github repo for that remote?

Human eyes don't move smoothly, they jump from place to place locking at target, that's why animatronics don't look natural.

Excellent project. I liked it

Looks like Clippy!

üíóüíóüíóüíó„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏è„Ä∞Ô∏èSmoooootttthhhieeeeee

It's a great tutorial. Really gives you a good idea how they animated Baby Yoda.

Now you just need to train a GAN neural net to learn different actors' facial tics and move the robot servos to match.

First order filtering FTW!

Exponential Moving Average

If you are working on creating a robotic arm, you should try to work towards programming a PID controller. It will give you much more control over how the arm moves.

@blackbomb64¬† PID is so next level. Thank you for the advice. Will give it a go :)

Have a look at https://youtu.be/ATQblGOjMWQ

There are interpolation functions that mimic better how humans and other animals move, but this video is showing a way to get decent results with a simple method.

A NN is overkill.  The only reason to use it would be to simplify the control system.  Train a network to match video frames of a face to keyframes of servo positions.  That would be a lot of work.  A GAN is 100% unneeded.

Exactly!  I use this to smooth out sensor readings for things like battery voltage monitoring, temperature sensors, and such.  James showed a simple representation of how to do this in code, but more info is available on Wikipedia: https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average

I agree- this is simple to implement in data reduction for things like rocket engine testing, and gives reasonable results. For archived data it can also be given a time shift to better align the output with large steps in the input data.

I think the loss of jitter improves effect vastly as well. You could read the speed of joystick movement as well, that would allow variable speed smooth movements. In operation sounds may elicit faster movement than vision. Cheers

I really would be interested in a Video covering a Motion Interpolating between two positions. Peferably in the Same style as this Video which I quiet Like.

Do you need the switch1Prev variable? You could just use switch1Smoothed, like so: switch1Smoothed = switch1 * 0.05 + switch1Smoothed * 0.95; The computation of the value returned will use previous value. You also don't need the parentheses.

This is perfect for my social distance Halloween project. Thank you

Useful videoü§ñ

In normal life, there is a acceleration at the start, a "constant" speed in the middle and a deceleration at the end.

Looking good is this the fraggle rock reboot? üòÅüëç

Here's something to try, though it will take a small bit of computation.  Have the eyes snap left or right quickly, and then have the neck turn more slowly in that direction, but counter-rotate the eyes as this happens so they appear to have locked onto looking at something, and the head then turns to consider it...

Make it interact with music, like a real  animatronic

FIVE NIGHTS AT FREDDY'S

I could just watch it move around for a long time. I didn't expect it to work that well!

Love your hard work on all your projects !

I live outside Chicago and i love the creators from other parts of the world! It's 1am and this pops up. So awesome lol Also your background music is pretty great

That creeps me out and i love it

wow

Would this be considered a complimentary filter?

Can you advice me a digital oscilloscope? üòä for beginners

Now you can put that to Bender?

"I'm going to publish all the cad and code for this if you'd like to HAVE A LOOK at it"  damnit

This was right in the middle of the uncanny valley

My limited knowledge of arduino tells me that this would work. But I think he knows this and chose to do it differently... For some reason.

Fun fact: human eyes won't move smoothly unless they are focused on a moving object (or what brain thinks is a moving object). At any other time eyes just snap to a new position very quickly.

@JTCF¬† Not a fact and why would it be fun for everyone if it was true.

@maxxsteele9396¬† it's absolutely true

‚Äã¬†@JTCF¬† Yes, but they will also move smoothly when you focus on a stationery object and then move your head.

@maxxsteele9396¬† how about you cite a source supporting your claim and refuting theirs, rather than resort to baseless insults?

@SamFisk¬† The burden of proof isn't on me since I made no claims. See how that works?

@maxxsteele9396¬† you dont need even need a source, just film a video of yourself looking around, then looking at something moving(or, as Martin Jones suggested, look at something stationary and move your head). Quick and easy way to test your theory.

@maxxsteele9396¬† also, I agree with Sam Fisk. Why did you straight-up insult the guy? if you think someone is wrong on the internet(about eye movement, which not a very hot topic), telling him he's on drugs and has a mental disability is not the appropriate response.

@maxxsteele9396¬† https://youtu.be/DkaJ6iK2CJc

@maxxsteele9396¬† This is the wrong community for your type of toxicity. Begone, before someone drops a house on you.

@iAmTheSquidThing¬† Yes, it's true, but it also can be seen as object moving relatively to human head, which is what it is for our brain. And I mentioned it in my original message.

I got this info from various sources, as well as noticing it on myself, and one of the best sources is already linked in one of replies.

@JTCF¬† also, something i've noticed on myself, anytime the eyes snap to a new target the eye lids seem to blink

@JTCF¬† "saccade" is the word for this.

"Anticipation" - Good set of basic animation videos based on "The Twelve Principles of Animation".  https://www.youtube.com/watch?v=F8OtE60T8yU

@maxxsteele9396¬† just ask your friend to try it out

that'd be awesome animation... also kinda creepy lol

@iAmTheSquidThing¬† Then the stationary object is moving relative to your head.

@maxxsteele9396¬† Provide proof that you don't have to prove it

Yes, also known as a single-pole smoothing filter.

@DanFitz777¬† because of the (single-pole) transfer function? That's cool, I'll have to look into this

why is this a problem?

@jameshughes3014¬† It's phunny

@experimentalcyborg¬† oh.  I am slow today

really ? i guess the valley is different for everyone

The fact that the uncanny valley exists means that at some point in evolutionary history it was advantageous for humans to be able to detect (and be afraid of) something that looked like a human but wasn't.

@MrGatlin98¬† yeah or, detect easily when one human isn't acting normally

What joysticks are you using for the controller?

The origin of fnaf üò≥

Wow thats eerily realistic, good job!

Boston dynicks should watch you videos

Nice

Mi likeüòÄüòÄüòÄüòÄüá™üá∏üëç

Very British

6th

Thus is useful!

E

I think he has a tutorial for that Edit: https://youtu.be/ATQblGOjMWQ

They are way better than this smh

@Hygix_¬† I have Boston dynamics dog and it is not as good as this.

@Notverygoodatall¬† that's a different categories of machine

@Hygix_¬† these are both robots

@Notverygoodatall¬† but different shape and use

Wow that's cool


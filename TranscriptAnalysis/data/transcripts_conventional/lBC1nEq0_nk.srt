1
00:00:00,000 --> 00:00:07,460
An important question that has to be answered when you're designing an autonomous system is how do you get that system to do what you want?

2
00:00:08,180 --> 00:00:10,500
I mean, how do you get a car to drive on its own?

3
00:00:11,000 --> 00:00:13,480
How do you manage the temperature of a building?

4
00:00:13,980 --> 00:00:19,400
Or how do you separate liquids into their component parts efficiently with a distillation column?

5
00:00:20,000 --> 00:00:23,900
And to answer those questions, we need control theory.

6
00:00:23,900 --> 00:00:30,700
Control theory is a mathematical framework that gives us the tools to develop autonomous systems.

7
00:00:31,100 --> 00:00:35,380
And in this video, I want to walk through everything you need to know about control theory.

8
00:00:35,760 --> 00:00:37,120
So I hope you stick around for it.

9
00:00:37,580 --> 00:00:39,860
I'm Brian, and welcome to a MATLAB Tech Talk.

10
00:00:42,080 --> 00:00:46,760
We can understand all of control theory using a simple diagram.

11
00:00:47,240 --> 00:00:50,980
And to begin, let's just start with a single dynamical system.

12
00:00:50,980 --> 00:00:58,560
This system is the thing that we want to automatically control, like a building or a distillation column or a car.

13
00:00:58,940 --> 00:01:00,380
It can really be anything.

14
00:01:00,840 --> 00:01:05,380
But the important thing is that the system can be affected by external inputs.

15
00:01:05,940 --> 00:01:09,320
And in general, we can think of the inputs as coming from two different sources.

16
00:01:09,860 --> 00:01:15,260
There are the control inputs, U, that we intentionally use to affect the system.

17
00:01:15,500 --> 00:01:20,880
For a car, these are things like moving the steering wheel and hitting the brake and pressing on the accelerator pedal.

18
00:01:21,460 --> 00:01:23,720
And then there are unintentional inputs.

19
00:01:24,200 --> 00:01:30,860
These are the disturbances, D, and they are forces that we don't want affecting the system, but they do anyway.

20
00:01:31,440 --> 00:01:33,800
These are things like wind and bumps in the road.

21
00:01:34,620 --> 00:01:42,100
Now, the inputs into the system interact with the internal dynamics, and then the system state X changes over time.

22
00:01:42,100 --> 00:01:50,940
So, for a car, we move the steering wheel and we press the pedals, which turn the wheels and revs the engine, producing forces and torques on that vehicle.

23
00:01:51,400 --> 00:01:57,760
And then combined with the forces and torques from the disturbances, the car changes its speed, position, and direction.

24
00:01:57,760 --> 00:02:08,280
Now, if we want to automate this process, that is, we want the car to drive without a person determining the inputs, where do we go from here?

25
00:02:09,060 --> 00:02:17,160
And the first question is, can an algorithm determine the necessary control inputs without constantly having to know the current state of the system?

26
00:02:17,160 --> 00:02:28,040
Or maybe a better way of putting it is, do you need to measure where the car is and how fast it's going in order to successfully drive the car with good control inputs?

27
00:02:28,420 --> 00:02:30,780
And the answer is actually no.

28
00:02:30,780 --> 00:02:36,600
Now, we can control a system with an open loop controller, also known as a feedforward controller.

29
00:02:37,520 --> 00:02:47,780
A feedforward controller takes in what you want the system to do, called the reference R, and it generates the control signal without ever needing to measure the actual state.

30
00:02:48,480 --> 00:02:55,820
In this way, the signal from the reference is fed forward through the controller and then forward through the system, never looping back.

31
00:02:56,240 --> 00:02:57,800
Hence the name feedforward.

32
00:02:57,800 --> 00:03:05,800
For example, let's say that we want the car to autonomously drive in a straight line and at some arbitrary constant speed.

33
00:03:06,340 --> 00:03:12,560
If the car is controllable, which means that we have the ability to actually affect the speed and direction of the car,

34
00:03:12,920 --> 00:03:16,400
then we could design a feedforward controller that accomplishes this.

35
00:03:17,080 --> 00:03:22,820
The reference, drive straight, means that the steering wheel should be held at a fixed zero degrees.

36
00:03:22,820 --> 00:03:28,740
And drive at a constant speed means that we depress the accelerator pedal some non-zero amount.

37
00:03:29,460 --> 00:03:34,220
The car would then accelerate to a constant speed and drive straight, exactly as we want.

38
00:03:35,180 --> 00:03:39,920
However, let's say that we want the car to reach a specific speed, like 30 miles an hour.

39
00:03:39,920 --> 00:03:49,300
We can actually still do it with a feedforward controller, but now the controller needs to know how much to depress the accelerator pedal in order to reach that specific speed.

40
00:03:49,620 --> 00:03:53,400
And this requires knowledge about the dynamics of the system.

41
00:03:53,980 --> 00:03:58,000
And this knowledge can be captured in the form of a mathematical model.

42
00:03:58,000 --> 00:04:07,900
Now, developing a model can be done using physics and first principles, where the mathematical equations are written out based on your understanding of the system dynamics.

43
00:04:08,520 --> 00:04:14,400
Or it can be done by using data and fitting a model to that data with a process called system identification.

44
00:04:15,160 --> 00:04:24,740
Both of these modeling techniques are important concepts to understand because, as we'll get into, models are required for almost all aspects of control theory.

45
00:04:24,740 --> 00:04:34,860
Now, as an example of system identification, we could test the real car and record the speed it reaches given different pedal positions.

46
00:04:35,460 --> 00:04:39,060
And then we could just fit a mathematical model to that data.

47
00:04:39,740 --> 00:04:43,640
Basically, speed is some function of the pedal position.

48
00:04:44,940 --> 00:04:52,500
Now, for the feedforward controller itself, we could just use the inverse of that model to get pedal position as a function of speed.

49
00:04:52,500 --> 00:04:59,740
So, given a reference speed, the feedforward controller would be able to calculate the necessary control input.

50
00:05:00,940 --> 00:05:04,720
So, feedforward controllers are a pretty straightforward way to control a system.

51
00:05:05,180 --> 00:05:11,700
However, as we can see, it requires a really good understanding of the system dynamics, since you have to invert them in the controller.

52
00:05:12,160 --> 00:05:16,740
And any error in that inversion process will result in error in the system state.

53
00:05:16,740 --> 00:05:25,500
Also, even if you know your system really well, the environment the system is operating in should have predictable behavior as well.

54
00:05:26,000 --> 00:05:32,300
You know, so that there's not a lot of unknown disturbances entering the system that you're not accounting for in the controller.

55
00:05:32,300 --> 00:05:41,480
Of course, it doesn't take much imagination to see that feedforward control breaks down for systems that aren't robust to disturbances and uncertainty.

56
00:05:42,180 --> 00:05:47,080
I mean, imagine wanting to autonomously drive a car across a city with feedforward control.

57
00:05:48,120 --> 00:05:56,920
Theoretically, you could map the city well enough and know your car well enough that you could essentially pre-program in all of the steering wheel and pedal commands.

58
00:05:57,240 --> 00:05:58,540
And just let it go.

59
00:05:58,540 --> 00:06:06,360
And if you had perfect knowledge ahead of time, then the car would execute those commands and then make its way across the city unharmed.

60
00:06:07,200 --> 00:06:09,900
Obviously, though, this is unrealistic.

61
00:06:10,540 --> 00:06:14,220
I mean, not only are other cars and pedestrians impossible to predict perfectly,

62
00:06:14,720 --> 00:06:24,600
but even the smallest errors in the position and speed of your car will build over time and eventually deviate much too far from the intended path.

63
00:06:24,600 --> 00:06:30,940
So this is where feedback control or closed loop control comes to the rescue.

64
00:06:31,760 --> 00:06:39,540
In feedback control, the controller uses both the reference and the current state of the system to determine the appropriate control inputs.

65
00:06:40,140 --> 00:06:45,560
That is, the output is fed back, making a closed loop.

66
00:06:46,020 --> 00:06:46,900
Hence the name.

67
00:06:46,900 --> 00:06:56,020
And in this way, if the system state starts to deviate from the reference, either because of disturbances or because of errors in our understanding of the system,

68
00:06:56,320 --> 00:07:03,320
then the controller can recognize those deviations, those errors, and adjust the control inputs accordingly.

69
00:07:03,880 --> 00:07:07,940
So feedback control is a self-correcting mechanism.

70
00:07:07,940 --> 00:07:16,660
And I like to think of feedback as a hack that we have to employ due to our inability to perfectly understand the system and its environment.

71
00:07:17,240 --> 00:07:20,980
We don't want to use feedback control, but we have to.

72
00:07:22,100 --> 00:07:22,580
All right.

73
00:07:22,680 --> 00:07:28,400
So feedback control is powerful, but it's also a lot more dangerous than feed forward control.

74
00:07:28,400 --> 00:07:37,000
And the reason for this is that feed forward changes the way we operate a system, but feedback changes the dynamics of the system.

75
00:07:37,360 --> 00:07:39,500
It changes its underlying behavior.

76
00:07:39,900 --> 00:07:47,400
And this is because with feedback, the controller changes the system state as a function of the current state.

77
00:07:47,780 --> 00:07:51,780
And that relationship is producing new dynamics.

78
00:07:52,400 --> 00:07:57,400
And changing dynamics means that we have the ability to change the stability of the system.

79
00:07:57,400 --> 00:08:03,980
And on the plus side, we can take an unstable or marginally stable system and make it more stable with feedback control.

80
00:08:04,260 --> 00:08:10,520
But on the negative side, we can also make a system less stable and even unstable.

81
00:08:10,940 --> 00:08:17,660
And this is why a lot of control theory is focused on designing and, importantly, analyzing feedback controllers.

82
00:08:17,840 --> 00:08:21,240
Because if you do it wrong, you can cause more harm than good.

83
00:08:21,240 --> 00:08:31,840
And since feedback control exists in many different types of systems, the control community over the years have developed many different types of feedback controllers.

84
00:08:31,840 --> 00:08:41,780
There are linear controllers like PID and full state feedback that assume the general behavior of the system being controlled is linear in nature.

85
00:08:42,620 --> 00:08:49,640
And if that's not the case, there are nonlinear controllers like on-off controllers and sliding mode controllers and gain scheduling.

86
00:08:49,640 --> 00:08:56,120
Now, often thinking in terms of linear versus nonlinear isn't the best way to choose a controller.

87
00:08:56,360 --> 00:08:58,900
So we define them in other ways as well.

88
00:08:59,420 --> 00:09:05,060
For example, there are robust controllers like mu synthesis and active disturbance rejection control,

89
00:09:05,220 --> 00:09:10,960
which focus on meeting requirements even in the face of uncertainty in the plant and in the environment.

90
00:09:10,960 --> 00:09:15,560
So we can guarantee that they are robust to a certain amount of uncertainty.

91
00:09:16,520 --> 00:09:24,720
There are adaptive controllers like extremum seeking and model reference adaptive control that adapt to changes in the system over time.

92
00:09:25,180 --> 00:09:30,220
There are optimal controllers like LQR where a cost function is created,

93
00:09:30,640 --> 00:09:36,780
and then the controller tries to balance performance and effort by minimizing the total cost.

94
00:09:36,780 --> 00:09:45,820
There are predictive controllers like model predictive control that use a model of the system inside the controller to simulate what the future state will be,

95
00:09:46,240 --> 00:09:52,140
and therefore what the optimal control input should be in order to have that future state match the reference.

96
00:09:52,800 --> 00:10:01,520
There are intelligent controllers like fuzzy controllers or reinforcement learning that rely on data to learn the best controller.

97
00:10:02,080 --> 00:10:04,080
And there are many others.

98
00:10:04,080 --> 00:10:07,340
And the point here isn't to list every control method.

99
00:10:07,720 --> 00:10:12,260
I just wanted to highlight the fact that feedback control isn't just a single algorithm,

100
00:10:12,540 --> 00:10:14,040
but it's a family of algorithms.

101
00:10:14,500 --> 00:10:22,480
And choosing which controller to use and how to set it up depends largely on what system you are controlling and what you want it to do.

102
00:10:23,620 --> 00:10:26,360
So what do you want your system to do?

103
00:10:26,740 --> 00:10:28,780
What state do you want the system to be in?

104
00:10:29,080 --> 00:10:30,920
What is the reference that you want it to follow?

105
00:10:30,920 --> 00:10:35,600
And this might seem like a simple question if we're balancing an inverted pendulum,

106
00:10:35,900 --> 00:10:38,780
or designing a simple cruise controller for a car.

107
00:10:39,280 --> 00:10:41,660
The reference for the pendulum is vertical,

108
00:10:42,100 --> 00:10:45,340
and for the car it's the speed that the driver sets.

109
00:10:46,220 --> 00:10:51,220
However, for many systems, understanding what it should do takes some effort,

110
00:10:51,560 --> 00:10:54,060
and this is where planning comes in.

111
00:10:54,060 --> 00:10:58,220
The control system can't follow a reference if one doesn't exist,

112
00:10:58,520 --> 00:11:02,040
and so planning is a very important aspect of designing a control system.

113
00:11:02,620 --> 00:11:06,800
With a self-driving car, for example, planning has to figure out a path to the destination,

114
00:11:07,060 --> 00:11:10,240
while avoiding obstacles, and it has to follow the rules of the road.

115
00:11:10,720 --> 00:11:14,180
Plus, it has to come up with a plan that the car is physically able to follow.

116
00:11:14,720 --> 00:11:18,100
You know, it doesn't accelerate too fast, or it doesn't turn too quickly.

117
00:11:18,100 --> 00:11:22,940
And if there are passengers, then planning has to account for their comfort and safety as well.

118
00:11:23,680 --> 00:11:29,220
And only after the plan has been created can the controller then generate the commands to follow it.

119
00:11:29,700 --> 00:11:35,040
An example of two different graph-based planning methods are rapidly expanding random trees,

120
00:11:35,460 --> 00:11:37,720
RRT and A star.

121
00:11:38,740 --> 00:11:41,620
Once again, there are too many different algorithms to name,

122
00:11:41,620 --> 00:11:45,720
but the important thing is that you understand that you have to develop a plan

123
00:11:45,720 --> 00:11:48,620
that your controller will then try to follow.

124
00:11:50,180 --> 00:11:52,660
All right, so once you know what you want the system to do,

125
00:11:52,840 --> 00:11:54,900
and you have a feedback controller to do it,

126
00:11:55,260 --> 00:11:58,000
now you need to actually execute this plan.

127
00:11:58,500 --> 00:12:02,720
And as we know, for feedback controllers, this requires knowledge of the state of the system.

128
00:12:03,160 --> 00:12:05,740
That is, after all, what we are feeding back.

129
00:12:06,080 --> 00:12:10,200
And the problem is that we don't actually know the state unless we measure it.

130
00:12:10,200 --> 00:12:13,800
And measuring it with a sensor introduces noise.

131
00:12:14,500 --> 00:12:17,880
So for our car example, we're not feeding back the true speed of the car,

132
00:12:18,060 --> 00:12:20,820
we're feeding back a noisy measurement of the speed.

133
00:12:21,440 --> 00:12:24,200
And our controller is going to react to that noise.

134
00:12:24,640 --> 00:12:28,860
So in this way, noise in a feedback system actually affects the true state of the system.

135
00:12:29,320 --> 00:12:33,400
And so this is one additional problem that we're going to have to tackle with feedback control.

136
00:12:34,060 --> 00:12:36,480
A second problem is that of observability.

137
00:12:36,480 --> 00:12:39,100
In order to feed back the state of the system,

138
00:12:39,420 --> 00:12:42,460
we have to be able to observe the state of the system.

139
00:12:42,760 --> 00:12:49,100
And this requires sensors in enough places that every state that is fed back can be observed.

140
00:12:49,720 --> 00:12:53,280
Now, it's important to note that we don't have to measure every state directly.

141
00:12:53,380 --> 00:12:55,500
We just need to be able to observe every state.

142
00:12:55,860 --> 00:12:58,020
For example, if our car only has a speedometer,

143
00:12:58,260 --> 00:13:02,320
we can still observe acceleration by taking the derivative of the speed.

144
00:13:02,320 --> 00:13:05,260
So there are two things here.

145
00:13:05,820 --> 00:13:07,760
We need to reduce measurement noise.

146
00:13:08,300 --> 00:13:14,340
And we need to manipulate the measurements in such a way that allows us to accurately estimate the state of the system.

147
00:13:15,000 --> 00:13:19,440
State estimation is therefore another important area of control theory.

148
00:13:20,100 --> 00:13:23,420
And for this, we can use algorithms like the Kalman filter,

149
00:13:23,920 --> 00:13:28,260
the particle filter, or even just run a simple running average.

150
00:13:28,260 --> 00:13:32,160
And choosing an algorithm depends on which states you are directly measuring,

151
00:13:32,160 --> 00:13:36,720
and how much noise and what type of noise is present in those measurements.

152
00:13:38,000 --> 00:13:44,660
Now, the last major part of control theory is responsible for ensuring the system that we just designed works.

153
00:13:44,980 --> 00:13:47,580
That it meets the requirements that we set for it.

154
00:13:47,760 --> 00:13:50,860
And this comes down to analysis, simulation, and test.

155
00:13:50,860 --> 00:13:58,420
For this, we can plot data in different formats, like with a Bode diagram, a Nichols chart, or a Nyquist diagram.

156
00:13:59,040 --> 00:14:02,320
We could check for stability and performance margins.

157
00:14:02,740 --> 00:14:06,260
We could simulate the system using MATLAB and Simulink.

158
00:14:06,520 --> 00:14:11,980
And all of these tools can be used to ensure that the system will function as intended.

159
00:14:12,940 --> 00:14:19,160
And so this full diagram here, I think, represents everything you need to know about control theory.

160
00:14:19,160 --> 00:14:25,420
You have to know about different control methods, both feedforward and feedback, depending on the system you're controlling.

161
00:14:25,960 --> 00:14:29,700
You have to know about state estimation so that you can take all of those noisy measurements

162
00:14:29,700 --> 00:14:32,720
and be able to feed back an estimate of system state.

163
00:14:33,220 --> 00:14:38,600
You have to know about planning so that you can create the reference that you want your controller to follow.

164
00:14:39,400 --> 00:14:43,940
You have to know how to analyze your system to ensure that it's meeting requirements.

165
00:14:43,940 --> 00:14:50,800
And finally, and possibly most importantly, you have to know about building mathematical models of your system.

166
00:14:51,000 --> 00:14:55,160
Because models are often used for every part we just covered.

167
00:14:55,380 --> 00:14:57,420
They are used for controller design.

168
00:14:57,760 --> 00:14:59,500
They're used for state estimation.

169
00:14:59,960 --> 00:15:01,180
They're used for planning.

170
00:15:01,440 --> 00:15:03,680
And they are used for analysis.

171
00:15:03,680 --> 00:15:09,600
All right, I always leave links below to other resources and references.

172
00:15:09,940 --> 00:15:11,240
And this video is no exception.

173
00:15:11,860 --> 00:15:15,820
And there are a bunch for this video since I mentioned so many different topics.

174
00:15:16,360 --> 00:15:21,620
And something I think is nice is that we already have MATLAB Tech Talks for almost every topic I mentioned.

175
00:15:22,100 --> 00:15:28,540
We have feedforward and PID and gain scheduling and fuzzy logic and Kalman filters and particle filters

176
00:15:28,540 --> 00:15:32,600
and planning algorithms and system identification and more.

177
00:15:32,600 --> 00:15:39,180
So if there's an area of control theory that you want to learn more about, I hope you check out the links below.

178
00:15:40,140 --> 00:15:45,240
And to make it easier to browse through all of them, I put together a journey at resorcium.org

179
00:15:45,240 --> 00:15:48,640
that organizes all of the references in this video.

180
00:15:49,140 --> 00:15:52,040
Again, link to that is below as well.

181
00:15:52,800 --> 00:15:54,700
So this is where I'm going to leave this video.

182
00:15:54,900 --> 00:15:58,860
If you don't want to miss any other future Tech Talk videos, don't forget to subscribe to this channel.

183
00:15:59,240 --> 00:16:01,580
And if you want to check out my channel, Control System Lectures,

184
00:16:01,580 --> 00:16:04,480
I cover more control theory topics there as well.

185
00:16:04,980 --> 00:16:07,020
Thanks for watching, and I'll see you next time.


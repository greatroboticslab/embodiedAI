Patrons and Channel Members already have next week's video - it's about openDog V2 walking !

Where can i find the ardiono code for turtlebot 3??

Nice video

how can i learn this? a course? pls

Sooo cool! First time I'm hearing about these Nvidia modules! I'm still WAY too amateur for that investment but it's definitely something worth looking forward to!

One advantage of the Nvidia card is it is not sold out the way Raspberry Pi 4s are these days!

question, can I plan a path without interacting directly with the laptop or pc, like voice recognition or some other stuff?

So a year has passed. Are you generally happy with ROS?

you taught them via captchas

kids, what operate system is this absolute robo-chad using here? take note!

I am currently conducting my senior project on Turtlebot3 Burger Mavigation Optimization. I set up everything following the official tutorial of ROBOTIS. The Turtlebot has no problem with SLAM. However, during navigation, it oscillates back and forth amd eventually aborts the mavigation process. Is there anyone who had the same problem ? I could not find any solution or insight that would help me online :)

Please anyone answer me,after completing the project robot still needs wifi to function the Ros or works offline after?

That's Amazing

4:45 This deep learning software need a little more training. It thought that your arm was a toothbrush with 86% of certainty!! :D

That's a garbage model tbh. It threw out a few things like "toothbrush" for your hands, and "Umbrella" for the smoke sensor...

Legit work

it's so impressive

In all these vision-AI demos I've see, I'd never seen DL change/enhance it's understanding of another object based on the presents of another. I guess this goes on all the time with the context of a "face" being inexorably (at least usually!) attached to head, and by extension a body (again, usually).

Can it do Hotdog and Not Hot Dog?

Is the Jetson image recognition have to be connected to the internet or once the code is written can it be mobile and offline?

nvidea deep "learing". better luck next time James ;)

"NVidia Deep Learing,"  ‚ÄúMany a true word hath been spoken in jest.‚Äù

James Bruton took ya long enough

@afs7863¬† 30 some years, whut you wan?  :P

@TheJeScast¬† so soon 1t will be us. ;) lears :P

Yes if you code it.

Does anyone else find the idea of building a robot that can patrol through an area dynamically, identify humans, and nerf blast them to be slightly apocalyptic?  To our robot overlords, I surrender and volunteer to grease your bearings. Be kind to us!

Sir, I am starting my research in self navigation and motion planning using deep learning. Can you please guide me a little.  Or just give me a direction. Please sir

Bhai apna phone number dhdo

Amazing sir amazing  Where you from

I used a Turtlebot 2 on the 1st semester of the bachelor in Robotics... No one explained us much, we worked in groups of 5 and 6, and they just assumed that it was likely that at least one in each group knew how to program, prior to entering the university (they were right for most groups). In my group I was the only one that knew how to program, but I had never heard about ROS, and it was very hard to understand it. But after you understand ROS, everything is very simple to program.  Our goal was to develop the program for a "Mars exploration vehicle", we ended up with one that could  autonomously explore take and send a picture every minute Analise color to detect possible mud vulcanos  (if it contains water, they may contain live) Upon detecting a volcano it would send a picture with the coordinates if it bump into something it would stop and check the surroundings, sending pictures and change to manual driving mode (Manual mode was tricky because of the distance between Mars and Earth)

this is priceless

One more great video. What is your background?

This really makes me wish this existed 20 years ago when I built my first Dalek. Speaking of which I reckon you'd do a fair job of making one of those. Mine had an old laptop for brains and loads of micro controllers for sensing and pariferial control. It had an airsoft canon for weapons, an old Kinect for mapping and visual data. For the body a rubbish bin turned upside down with styrofoam balls cut in half works nicely.  I'm sure you can work out the rest. Anyway great content mate.

Elon will send you on the way to Mars.

Can you recognize and translate text?

Great video, as usual. Love your work, you always inspire me to get back into my projects. I‚Äôm working as well on a robot dog concept, based on MIT mini cheetah actuators. I would recommend trying to migrate to ROS2. ROS1 is still widely used, but it‚Äôs aimed really at research and development. So it still fine to use, but ROS2 is built to be more dev to production compatible and offers much more robustness to communications dropouts and natively supports higher reliability with the data distribution service middleware quality of service. Allows you to detect when nodes aren‚Äôt running as expected or messages are not arriving when you expect. Something to consider. TBH, ROS1 is still what I use mainly, old habits die hard, but I‚Äôm trying to move to only ROS2 to help handle what i spoke to above.

Guys...I read thru and see many posts about why "toothbrush, kite, arm, bed, table..etc."  Look, assume the AI model is only trained for 2 things: 1) a hand, and 2) a bed. Pretty simple right? Now, whatever you show the AI model, it HAS to pick one of the two items. So, doesn't matter what it is, I have to pick 1, or 2...so if you show me something squarish..., I'm going to say it's a bed....or if you show me something squiggly, I'll say it's a hand...AND I'll be very confident, because I only have 2 choices...If it's square"ish"...then it MUST be a bed, I have no other choice, because it certainly isn't a hand....Got it now?

What joysticks are you using there, they look pretty nice..

Yep, there clearly was a toothbrush, an airplane, an umbrella and a kite in your room for excatly one frame. I am 70% certain that is true.

My follow was recommended by: Mark Rober

Please answer me , why you pluged in an arduino uno into raspberry pi 4??

Excellent

OMG I'm in love with that robot

Its crazy how  many times I have been interested in a subject, and next thing I know, you are putting a video out on said subject!!! I am taking a Shark Ion RV750 robot vacuum, and turning it into a Snark ROS vacuum robot!

Thanks  https://www.youtube.com/watch?v=dkNpJnxTZls&t=18s

Fantastic video James! And your links for robotics courses and deep learning projects? Awesome! You've created a great resource here. Great way to get started. Inspiration my friend. Thank you!

Amazing I'm going to be making robots using these

Pretty cool and also scary. One step closer to slaughter bots!

Why don‚Äôt you make a tf2 sentry

Anyone used the turtlebot 3 burger on carpet area? I am planning to buy it so just need some input on that

imagine being able to do this with our Droids from Disneyland's Droid Depot

The Nano has two camera connectors to be able to do VR 180 and 360.

Hey James. Great video. I love ROS and I have a small tip for you. After a while, you will get many terminals running nodes, can be quite messy and confusing to keep track of every thin. Then if that happens you should try using Tmux. Its a terminal multiplexer allowing you to have multiple terminals in the same terminal. Also if you use Tmux over SSH the terminal int lost if you accidentally are disconnected. Can save a lot of headaches.

so were can i start in robotics course i see the field is so broad

wow  that was so good.

its a first step to a robocop, hopefully its not reprogrammed to identify black or white persons

I am actively looking for building a cheap ros based ronot.

Hey, I was just recommended your channel and subscribed, because what your're doing is relevant to my interests. Looking through your content, it doesn't seem like you go through your code when making these machines. I hope you do. Thanks!

I look forward to seeing how you get the Pi Camera + ROS working on Pi 4.  I struggled with this for some time.  I tried a few months back and found I could get Ubuntu 18.04 onto a Pi 4 the install ROS, but could not get raspicam_node to work.  I then tried installing Raspbian Buster on the Pi 4, compiling ROS from source and then hacking  Raspicam_node  until it installed.  That worked, but I was an emotional wreck by the end !  I would love to see an easy solution, installing from binaries.  A Pi 4 + ROS + Camera is a great combination for robotics.

I just backed an OAK-D on kickstarter. It is a dual camera Open CV AI kit with stereo depth perception. Might make a good dog brain.

Best of luck, gonna be a lot of work but you are surely up for the task!

Can I use an arduino with NRF24L01 and my computer as base for de ROS navigation system?

4:39 - it thinks your hands are toothbrushes, and at 4:46 it thinks your arms are airplanes... not parts of a human! :P

Great review.  First application is weaponization of the robot!

hi james bruton i have just found this video for you to have a look at https://www.youtube.com/watch?v=8BtDuzu2WeI

I have a series coming up soon

@jamesbruton¬† thank you James , I don't find best ways to ros any where internet. I am hoping the best from you.

Sometimes I do, but in the case of Robot dogs I've done it so many times in previous builds I don't cover it again unless it's new.

@jamesbruton¬†  Alright, I will do some digging through your videos over the weekend.

This project is mental.  Thanks!

Hey I‚Äôm curious did you say you could use just about any camera to identify an object with the first program? Would you able to use it with a computer‚Äôs inbuilt camera?

Now you can make your Ironman suit autonomous and summon it.

I'm trying to build a life sized robot with servo motors any advice for a beginner trying to build a robot?

No, it doesn't know that you're a human. Please tell us exactly what it really does know.  It's something like 'a moving object radiating a certain range of temperatures' or something like that. Let's get, and stay, real, shall we? Thanks.  I'll be liking your stuff much more when you step away from killer robots.  How about 'Petting robots' or 'joking robots'. Enough with the killers.

that is just perfect for a nerf-gun control :D now need to identify where the different body parts are to aim better ^^ great project, thanks for introducing! edit: oh wow, at 16:00 you're already showing a controlled nerf-gun O_O ok... nice!

You look like the oldest 12 year old ever.

Amazing!!!!!!!

4:50 - for 1 frame you were a toilet with 91% certainty LOL

Haha with only the arm in the frame it flashes "airplane" and "kite".

A ROS series?!! This is going to be quite the ride, can't wait to see the next episode

For those not able to purchase the turtlebot 3 - the eManual for the TB3 contains a lot of simulation stuff, you can learn an awful lot from using a simulated robot in gazebo, all the ROS nodes function the same. It's also free.  A caveat to that though, is that you won't get the sensor ambiguity that you get in real life, for example the map that the TB3 produced will look a lot better in sim than in real life, but then again it will look a lot better if you use a better LiDAR.

Dear Sir, if you really want to make and have fun join me at crazyvisionaries dot tech We are moving a paradigm shift in personal robotics with Dr. Benosman machine vision tech and the end of batteries for robots by converting energy directly from space. email me if you would like the details.

ROS2 ecosystem is growing. You should give it a try as well. I was turned off ROS1 due to protocol overhead but ROS2 is more efficient, realtime capable, and simpler node design. It also has microROS for arduino nodes. Community is not as far along as ROS1 but it's growing fast and we recently got MoveIt!2. I am using it on my humanoid robot.

When did you start coding?

Can someone please stick this guy in a T-800 skull....this would be great lol

T-800 already had 40 years back...

quality content ya got here

surfboard 61.8%, toothbrush 72.6%, airplane 68.9%, umbrella 64.3%, cat 61%, skateboard .... yeah

James, please update to python3. Thanks.

Or you just do you and let other do what they like.

That's great, thanks alot üòç but how cleaning machines work without laser üòïü§î

Love to see more ROS stuff. It's pretty cool

Why did I just watch a video of a toothbrush?

Ubuntu is pronounced oo-b-oo-n-t-oo. Its an African word. Not you-buntoo

Toothbrush 85%, Kite 55%

Sub and bell

I hope you got sponsored for a lot of videos on this product! Seriously! ^_^

Personally y prefer hector-slam over gmapping is it a more lightweight node yet it works as best if not better than gmapping. Finally goggle's cartographer is the top mapping library but it is way to complex for my liking a bit of an overkill really

Really interesting video can‚Äôt wait for you to upgrade some of your other projects where you had an idea but the technology

Just don't tell the robot, "Bring me the baby."

Thumbs down for nvidia. I'm tired of "Off topic" being a new Nuremberg defense for not being ethically responsible. Nvidia is a shitty company and with a platform of nearly a million subs James shouldn't be giving them legitimacy in an OSS/DIY space.

I have a solid year of work using ROS 1 for a research paper in college.  I found the possibilities with ROS are truly endless where robotics are concerned... if you can dream it you can program it in ROS that said it also took me a solid 2 months of working on my own to get a good understanding of it before was able to really get going on my project ROS is a wonderful platform if you want to put in the work.

Hmm.  Considering the direction you're going, you may want to include a microphone on your new remote.  I can imagine the need for issuing remote voice commands emerging in the near future.  :)

Hot damn Jamie boy your content it activates the almonds. Noice marble floors, you got a loiscence for that mate?

Where did you get this stuf?

if you're using ROS for messages and topics you could use MQTT instead does exactly that

5:25 - I'm so looking forward to aural AI (to add to visual AI) that will listen for surfaces that would hear the cup on a table and would say 'Beds are soft, this has to be a table!'.

Nice to see you get started with ROS, it will bring your projects to the next level. I'm a professional robotics engineer and work daily with ROS so if you need any help, let me know.

looking forward to the incorporation of this new layer, great stuff James, thanks!

4:30  ‚ÄúAnd hopefully we see that it detects a human.‚Äù  holds breath  detects James as human  Welp one less possible android to worry for the robot uprising!  If it detected James as a robot, I‚Äôd be very nervous indeed!

Can you give me any advice? I am a beginner in ROS and want to apply this to robotic manipulation in manufacturing

@jouleio4525¬†  It has an extremely steep learning curve and I found that for ros 1 after you get past the basic tutorials support kinda evaporates. I would strongly reccmond you look at the construct they have free weekly webinars and other stuff However some of it is behind a pay wall They are really the only source of Info for the more advanced stuff Given it's open source nature the doccumation while not horrid is not particularly amazing particularly when  it comes to the more advanced stuff I also strongly reccmond that you have a high end computer. Particularly if you are going to be using a VM to run linux to talk to the robot I was regularly using more than 20 gigs of ram running the vm and ros. The same goes for the processor. I would reccmond an i7 or equilivent However 16 gig and an i5 would suffice for most The other bit is that huh ou dont need to upload your code to the robot every time you run it Because of the de centralized nature of ros you are able to run the code for the host computer running the server As for starting platforms I would reccmond using the robotis turtlebot  It is about 1300 usd and is plenty to learn the platform/explore it before investing in a more expensive platform There are also other platforms that are already made for indstural applications that you might want to look into Most are mobile platforms for moving materials but tbere as re also a coupple of as arms too I believe Baxter is one of them It has 2 arms and a screen with eyeballs Anyways hit me up if you want more info

@natpim4730¬† Thankyou very much for replying hahah üòÄ. fortunately, I took the course at RobotIgniteAcademy and still learning for ROS with python. I often hear about the turtlebot. Currently I am interested in dobot magician, its a 3 axes desktop robotic arm. It is written that it is also support ROS. You can also check this things out. I am curious about the future career of ROS engineer especially in South East Asian countries since I am from these regions. Also what I noticed is that the high development of ROS still occur in developed countries such as USA, Europe, China.

‚Äã¬†@jouleio4525¬† the turtle bot has a 6? axis arm that can be mounted ontop of it... as far as the jobs go yes there are ros development jobs for the usage of ROS in indstural environments however I don't know what the field looks on the other side of the pond where you are And why are you using python.... C++ is much much better.... manny more options with what you can do....

@natpim4730¬† The thing is I want to master the concept of ROS as quick as possible, and at first I am not familiar with python and C++.Thus, I choose python to start with ROS since the language is easier than C++. (I know that C++ is much better for robotic software engineer  careers )

@jouleio4525¬† That is understandable I might have done waayyy too much C in college.....

Definitely another promising avenue of robotics to delve into and definitely one I'd be interested in seeing you persue. Man this has to be folded back into some of the past projects for sure. R2 unit with these capabilities, open dog with these capabilities, BB8.

Youre such an inspiration man

Why is that toothbrush flying a kite indoors? Such a weird video :o

Ubuntu is actually pronounced ‚ÄúOoboonto‚Äù.https://www.lexico.com/en/definition/ubuntu

cool! I bet I could use this to make a quad copter seek out red light traffic cameras and shoot them with a laser.

Hi ! I'm very happy to see you learning ROS. To control your Robots you can use Xbox Controllers with the  "Joy" node. It is almost plug and play since the remaining thing to do is to convert joysticks readings from the "joy" topic to twist message and send it over cmd_vel.

Fascinating stuff! If it can detect chickens, I could use it for a chicken coop door!

4:15 not done python from a long time but "for detection in detections" is useless if you use only the first one, an if should be more efficient

it recognised you smoke detector base as a kite! where is the smoke detector?

Would it be possible to use ROS for a smarter lawnmower that uses a precise mowing path that's the most efficient, this in contrast to how most mowers work now..? Maybe have easy anchor points that can be recognised for orientation?

This is how Skynet started.

loving this - lots of new ideas and hardware - havent seen you use linux or raspberry pi's much in the past...the ros lidar navigation node looksrealy useful!

You should definitely check out AlwaysAi. You can use all kinds of deep learning models and even train your own.  I‚Äôve been using it for a while and it supports Jetson Nano, GPUs, and RasPis. Very flexible, easy to use

Sounds like a cool project ...

Could you make an in-depth tutorial to do slam on a pi 3b? I spent a lot of time trying to get it to work with no progress

Who else noticed creepy Elmo in the background 12:16

4:39 ... Aside from mistaking your arms for toothbrushes ... maybe you should work out more.

I wish you would publish a book for getting started in robotics. You truly are amazing.

Toothbrush and kite lol

maybe this project will convince james to stop doing everything on arduino first.  the only problem with that tho is that he says "raz bury pi"

Yeah true we need another bb8 robot

thanks, I've got more coming up!

thanks, I will check it out!

Yep, I have a two-part series coming up in a couple of weeks

Agreed

Make it happen!  Maybe do a kickstarter. That would be awesome!

agreed

wtf are you talking about, this guy is at most mediocre: autonomous vacuum cleaners been doing this for over 10 yrs now, most of them run linux, so what is the point of "reinventing the wheel"?! also, the only true power of distributed computing is that many hosts send sample data to centralized server that replies with item identification and keeps teaching the gann at same time, why have a local server with partial data?! also, why would want a book or a tv show - both are things of the past...

‚Äã¬†@cokeforever¬† know anyone that explain in a way beginners could easily understand.

How much is that ros robot in dollars?

He reminds me of Jacob Rees-Mogg for some reason...

Can you do a video on the adeept rasptank and see what can be done with it?

That doesn't look like Ubuntu 18.04 to me. Looks like 16.04 because of the unity launcher... (The one at the beginning on the Jetson nano, that is, the one at the end of the video is 18.04)

Awesome video is always

I'm sort of sadenned that Nvidia didn't sponsor this, but ah well. Maybe it will lead to them taking an interest in your work later.

Building a slam robot from scratch with ROS is my current project also, excited to see how you go about it. Please go in depth about the code and ROS implementation

Plug this into the sonic the hedgehog robot.

I would suggest to use ROS2 which has less overhead

What happens to the turtlebot if you put the box at the spot where it was supposed to stop, after the initial calculation of the path? does it stop before or after the box instead ?

It's frightening that the code reads "HUMAN DETECTED" lol. We are writing the codes for our future Terminators!

I look forward for what is to come out of this üëç

Want a AI with security camera to keep shots of 6ft toothbrush in my backyard! off to research!

Funny that it has recognized your arm and hand with 86.8% accuracy as a toothbrush.  üòÅ

You are now stepping into a higher class of robotics. Very nice. I hope that you make a lot of tutorial on ROS and robots using it. The tutorial out on ROS are at the moment, if free, very scientific and hard to understand. So we all need you as knowledge transfer person. Thank you!

Do the batman suit

Êó•Êú¨„Åã„Çâ„ÅÆ„Ç≥„É°„É≥„Éà„Åß„Åô„ÄÇ ÊúÄÈ´ò„Å´„ÇØ„Éº„É´„Å†„ÅúÔºÅ

SLAM that likebutton?

Where can I get those joysticks which you use in your remote?

You might also want to test the Sipeed range of AI boards. They use the K210 processor that is designed for AI. They out perform both options u have tested here but cost much less. See the range here https://www.seeedstudio.com/sipeed. and here is just 1 of the many videos explaining them a little https://www.youtube.com/watch?v=GX6euKNH2iE

yep - it's coming up in a couple of weeks

It keeps trying to get to the target going back and forth and trying again. You can de-tune the accuracy for getting to the target though so it thinks it's near enough

also as an airplane with 68.9%

that is the plan!

eBay '3 axis joystick'

Nice video, I've been working with ROS for a year to build an autonomous car. What I've learned over the year is that if you're using ROS on only 1 system, it's best to make use of Nodelets instead of nodes, as it sends pointers to messages in memory instead of serializing and deserializing the messages. Also, rosbag is love (for debugging).  ROS is switching to ROS2 though, which brings, apparently (haven't tried it yet), a lot of improvements, not sure if turtlebot will be switching to it aswell.

People who know nothing of AI: AI will take over the world!! AI: 4:45

Excellent video! Nice Jetson Nano setup! :) Big big thank you for the brief ROS introduction!!!

I swear you are one good day away from becoming iron man.. Or one bad day away from becoming a super villain.. It could go either way ü§∑‚Äç‚ôÇÔ∏èü§£

In order to learn ROS, I've been trying to do exactly what you said: build a robot with ROS on it and try to implement everything from scratch. This was a couple of months back. I've got quite far, but not nearly enough to the smoothness and accuracy of TurtleBot. I'm really looking forward to what you'll come up with :D

Project idea -   robot mower hack...   DIY opensource approach without the need for a boundary cable?

Ubuntu pronunciation: https://www.youtube.com/watch?v=UT-3Eh65kkA

Have you also checked the Maixduino from Sipeed or the Huskylens from DFRobot. They are Eur 20 and Eur 40 each and have lot of neural nw hw in them - its based on a Kendryrte K210.

James gettin into AI... looking forwad to see your microcomputer deepl projects <3

Amazing! Can't wait to watch the series, not a lot of great ROS content out there.

This is exactly what i was looking for for my next project. I want to build a robot with a tank base, and an arm on the top with i want it to have image recognition etc and be able to map out the area. can the laser module map in 3d or is it just 2d?

There is stuff for ROS to work with quadruped robots: https://github.com/chvmp/champ and several other packages.

I like it, you are going deeper and deeper into robotics by building you technology block! You should look at the coral board. Coupled with a rpi4 it have impressive performances for deep learning vision recognition. This is what is used into the reachy robot (which is open source). Also you should look at Luos witch is an alternative to serial_ros with a lot more possibilities including reusability of all your projects together.

James! Did you by any chance get to see the older ballbot model? https://www.youtube.com/watch?v=8BtDuzu2WeI  It's a beautiful concept, and even though I'm quite sure you've already seen it, this machine looks like it has something.

turtlebot3 looks great.  eep  over $1k australian

4:45 ‚ÄúToothbrush‚Äù

Ros 2 is also amazing, it is more focused around swarms and dynamic node allocation, because there is no longer a master required, and it has dds as middleware to improve security

okay, this is next-level.

You're only 97% human, the rest 3% was your bottom half..... ü§£  So I guess a human head is more than 75% of the human? ü§î I can already see robots saving only our heads, in pickle jars! ü§£ü§£ü§£

I had a project during my stay at a University of Applied Sciences toying around with ROS. It was so damn impressive to see how quickly you can setup a working robot doing awesome stuff

There are already ROS2 instructions for Turtlebot, but I'm not quite there yet

I'll make sure I have toothbrush disguise ready!

I'm 68.9% sure that it was an airplane though

To be honest, my face recognition/eye detection pan/tilt camera, is pretty impressive.It knows the faces I train it on, and can name/track them no problem. I got it working with lessons from paul mcwhorter here on youtube. I can even draw overlays over the eyes and stuff. I bought a laser to attach to it, but I haven't yet. His tutorials are currently on object detection, which I also have working a little bit, but not as well as the facial recognition. I have had people cover more than half their face and still be identified correctly.   Yeah though, it's going to take over the world, and for most big data analysis it already has. Even cities around the world have already been applying facial, gait, color, recognition for years.

Thanks!  I'm working on a more detailed ROS series to build a robot from scratch that can navigate.

James Bruton this would be super interesting!

I'm working on my own build from scratch right now, but I think there will be a V2 ;-)

thanks, I'm working on it!

That one is just 2D, you'd need a depth camera or a 360 3D laser scanner, and a different mapping solution

I'm working on a build fro scratch to do the same

4:50  "Toilet"

@idont3282¬† wow

Fantastic VIDEO !!! THANKS JAMES !!!  ... love the AI bits, looking forward the next one ...

I would recommend that you put a good (sizeable) heatsink and active cooling with a fan on the Raspberry Pi 4. Without active thermal cooling, the performance of the Raspberry Pi will be significantly compromised (i.e. any significant compute load lasting more than a minute or two will result in the CPU throttling back to 600MHz) . . . with active cooling, you can overclock the RPi4 and consistently run at 2.147GHz !  The Argon One case is a good option in that it provides a very effective passive heatsink (the metal case) with a variable speed fan that kicks in under software control dependent upon CPU temperature. I am also very impressed with the Yaboom RGB Cooling HAT  (does not use GPIO, but requires i2c for control), but this needs to also be paired with a large heatsink (e.g. aluminium heatsink case).

So glad to see the next logical step for your awesome projects! I could totally see the Performance Bots using the Nano's recognition of body poses to mimic people and dance with them.

That‚Äôs a noise little robot!

Thank you for the longer video üôå

Ah yes. The jetson nano. Or... Apparently, what the earliest Nintendo Switch dev kits consisted of. XD I guess if you wanna get some idea of what a Switch can do without hacking one, buy a Jetson Nano... Also... Xavier NX? Really? XD  (if you're unaware or have forgotten, NX was the codename for the Nintendo Switch before they released more information about it.)

Will you try out the Issac SDK from the Nvidia nano? I am thinking which platform should I use for my robot: ROS or Issac if I am using Jetson as my control unit.

It's pronounced / äÀàb änt ä/, like the "oo" sound in "look".

Genius

Liked even  before watching  waiting for the next part

Good morning

Hi, just got the noti....

Patrons and Channel Members already have next week's video - it's about openDog V2 walking !

Great stuff! I'd love to try to use ROS to make a robot vacuum, lawnmower, and snowblower!

Yeah quality work.  failed to get Ros running under windows. I'll retry on Linux then

It did detect you as a toothbrush at 4:35 :-D

That deep learning image recognition is impressive. The fact that the color indicator / overlay for the recognition of humans is RED triggers a slight feeling of unease, though - "Terminator" view activated ... xD

Great update/project üëçüòÄ Thanks for sharing üëçüòÄ

Great minds!  I've been learning ROS for my PiWars robot, I ended up building a custom controller for it too using those sticks and a bunch of buttons from an old RC controller: https://youtu.be/IVjZC8gXzgY?t=1222 My understand of ROS was incredibly naive in that video but I've since signed up for the Robot Ignite course too and learning to do things properly.  Very much looking forward to seeing your progress as a result :)

I really look forward to seeing your journey of discovering ROS. The possible applications look really interesting. Great informative video! Can you get the deep learning to identify a specific face so that you could denote a particular person as not a target?

You can run ROS on a Jetson board just as well. I've spent some time trying out NVidia Isaac and found it severely lacking documentation and not being developer friendly. The pre-built neural nets are nice, but not a killer feature. There is an Isaac-ROS bridge included with Isaac, but that is implemented poorly, eg. hiding exceptions etc. Also, ROS has a large community to ask questions etc.

@LoyvanBeek¬† So, i would better use ROS to develop my robot instead... I have seen the video from Nvidia developer of using the Issac SDK, seem the functionality is quite similar, well if there is not much document, then ROS seem is a better approach. Thanks

@LukTzeChing¬† The similar functionality seems only in a first glance. When you start to develop anything more complex than they pre-cooked for you, it's really difficult or impossible.

nvidea deep "learing". better luck next time James ;)

"NVidia Deep Learing,"  ‚ÄúMany a true word hath been spoken in jest.‚Äù

James Bruton took ya long enough

@afs7863¬† 30 some years, whut you wan?  :P

@TheJeScast¬† so soon 1t will be us. ;) lears :P

Please make this a project James, like a thunderbirds 4 with swapable parts!

lawnmower robot would be so cool!

You can without hardware as it comes with a decent simulator as you can run the roscore ( broker ) and the ros nodes on the same machine.  Turtle bot has always been stock and you can customize it and control it or make it autonomous if you wish,  Adding nodes ( camera's / other sensors ) is easy,   ROS is not as hard as you think, you only have to get your head around brokers pub/sub like MQTT.  Just one other thing starting out use Python but when working as needed port it over to C++ as that is where all the power is.

Vacuum doesn't use laser, it uses IR as I think üòÅ

I've not tried it, but it's better supported under Linux. You could always use VMware (free) Player to install Ubuntu

@jamesbruton¬† it's cool. my machines a dual boot. Honestly just gutting out a few python versions could probably get it but meh, I'll try penguin.  This was a genuinely exciting video for me. at last, some basic AI rammed in those mechanoid skulls.  We can easily harness an extant OS to some cheap fast processor at some point to remove the PC link.  Exciting times sir.

@jamesbruton¬† Quick update, was fine on linux, so tried on WSL with a windows X server. seems fine. Hope that helps.

@jamesbruton¬† Final update, building from source was easy to get a 32 bit version also. great code. nice project.

it's all about certainty and context pretty sure it would have pegged him as human before applying the (Insert brand name of toothpaste here)

@daniel_4096¬† What about when at 4:50 he's detected as a toilet with 91.3% probability

63.3% ToothBrushüòÇüòÇüòÇüòÇ

You can get similar results from alot cheaper hardware and is more open source with better open source support like Yolo,TF,Keras among others.

The video says it was posted 2 days ago and yet your comment shows a week ago... what the hell did you do lmao

@Sifu-Myers¬† They're probably patrons, so they got early access.

@donnawander7710¬† good point that makes more sense haha

looks good, I'm working on more of mine really soon!

Yes you could train the model to do anything, but that takes a while and would require a lot of images of the person in different environments.


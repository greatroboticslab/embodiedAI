1
00:00:00,880 --> 00:00:05,000
Let's talk about the Linear Quadratic Regulator, or LQR control.

2
00:00:05,000 --> 00:00:10,000
LQR is a type of optimal control that is based on state space representation.

3
00:00:10,000 --> 00:00:13,660
In this video I want to introduce this topic at a very high level so that you walk away

4
00:00:13,660 --> 00:00:17,820
with a general understanding of the control problem and can build on this understanding

5
00:00:17,820 --> 00:00:20,080
when you're studying the math behind it.

6
00:00:20,080 --> 00:00:25,040
I'll cover what it means to be optimal, how to think about the LQR problem, and then I'll

7
00:00:25,040 --> 00:00:29,000
show you some examples in MATLAB that I think will help you gain a little intuition about

8
00:00:29,000 --> 00:00:30,000
LQR.

9
00:00:30,000 --> 00:00:34,060
I'm Brian, and welcome to a MATLAB Tech Talk.

10
00:00:34,060 --> 00:00:37,820
To begin, let's compare the structure of the pole placement controller that we covered

11
00:00:37,820 --> 00:00:40,940
in the second video and an LQR controller.

12
00:00:40,940 --> 00:00:44,460
That way you have some kind of an idea of how they're different.

13
00:00:44,460 --> 00:00:48,580
With pole placement we found that if we feed back every state in the state vector and multiply

14
00:00:48,580 --> 00:00:53,400
them by a gain matrix K, we have the ability to place the closed loop poles anywhere we

15
00:00:53,400 --> 00:00:57,800
choose, assuming the system is controllable and observable.

16
00:00:57,800 --> 00:01:01,700
Then we scaled the reference term to ensure that we have no steady state reference tracking

17
00:01:01,700 --> 00:01:02,860
error.

18
00:01:02,860 --> 00:01:08,540
Now, the LQR structure on the other hand feeds back the full state vector, then multiplies

19
00:01:08,540 --> 00:01:12,520
it by a gain matrix K and subtracts it from the scaled reference.

20
00:01:12,520 --> 00:01:18,540
So as you can see, the structure of these two control laws are completely diff- well, actually

21
00:01:18,540 --> 00:01:20,220
no, they're exactly the same.

22
00:01:20,220 --> 00:01:25,600
They are both full state feedback controllers, and we can implement the results with the same

23
00:01:25,600 --> 00:01:29,500
structure from both LQR and pole placement.

24
00:01:29,500 --> 00:01:31,460
Now, a quick side note about this structure.

25
00:01:31,460 --> 00:01:35,900
We could have set it up to feed back the integral of the output, or we could have applied the

26
00:01:35,900 --> 00:01:38,380
gain to the state error.

27
00:01:38,380 --> 00:01:43,120
All three of these implementations can produce zero steady state error and can be used with

28
00:01:43,120 --> 00:01:45,780
the results from pole placement or LQR.

29
00:01:45,780 --> 00:01:49,420
And if you want to learn more about these other two feedback structures, I left a good source

30
00:01:49,420 --> 00:01:50,420
in the description.

31
00:01:50,420 --> 00:01:53,060
Okay, we're back.

32
00:01:53,060 --> 00:01:56,800
So why are we giving these two controllers different names if they're implemented in

33
00:01:56,800 --> 00:01:58,560
the exact same way?

34
00:01:58,560 --> 00:01:59,920
Well here's the key.

35
00:01:59,920 --> 00:02:05,440
The implementation is the same, but how we choose K is different.

36
00:02:05,440 --> 00:02:10,240
With pole placement, we solved for K by choosing where we want to put the closed loop poles.

37
00:02:10,240 --> 00:02:14,360
We wanted to place them in a specific spot, and this was awesome.

38
00:02:14,360 --> 00:02:18,720
But one problem with this method is figuring out where a good place is for those closed loop

39
00:02:18,720 --> 00:02:19,720
poles.

40
00:02:19,720 --> 00:02:24,400
And this might not be terribly intuitive for high order systems and systems with multiple

41
00:02:24,400 --> 00:02:25,400
actuators.

42
00:02:25,400 --> 00:02:29,040
So, with LQR we don't pick pole locations.

43
00:02:29,040 --> 00:02:34,720
We find the optimal K matrix by choosing closed loop characteristics that are important to us.

44
00:02:34,720 --> 00:02:39,340
Specifically, how well the system performs and how much effort does it take to get that

45
00:02:39,340 --> 00:02:40,780
performance.

46
00:02:40,780 --> 00:02:45,080
And this statement might not make a lot of sense, so let's walk through a quick thought exercise

47
00:02:45,080 --> 00:02:46,680
that I think will help.

48
00:02:46,680 --> 00:02:50,680
From borrowing and modifying this example from Christopher Lum, who has his own video on

49
00:02:50,680 --> 00:02:54,920
LQR that is worth watching if you want a more in-depth explanation of the mathematics.

50
00:02:54,920 --> 00:02:57,280
I've linked to his video in the description.

51
00:02:57,280 --> 00:02:59,680
But here's the general idea.

52
00:02:59,680 --> 00:03:03,720
Let's say you're trying to figure out the best way, or the most optimal way, to get from

53
00:03:03,720 --> 00:03:04,680
your home to work.

54
00:03:04,680 --> 00:03:08,040
And you have several transportation options to choose from.

55
00:03:08,040 --> 00:03:12,680
You could drive your car, you could ride your bike, take the bus, or charter a helicopter.

56
00:03:12,680 --> 00:03:16,680
And the question is, which is the most optimal choice?

57
00:03:16,680 --> 00:03:20,920
Well, that question by itself can't be answered, because I haven't told you what a good outcome

58
00:03:20,920 --> 00:03:21,920
means.

59
00:03:21,920 --> 00:03:26,280
All of those options can get us from home to work, but they do so differently, and we need

60
00:03:26,280 --> 00:03:28,680
to figure out what's important to us.

61
00:03:28,680 --> 00:03:34,040
If I said that time is the most important thing, get to work as fast as possible, then the optimal

62
00:03:34,040 --> 00:03:36,680
solution would be to take the helicopter.

63
00:03:36,680 --> 00:03:40,200
On the other hand, if I said that you don't have much money and getting to work as cheaply

64
00:03:40,200 --> 00:03:44,680
as possible was a good outcome, then riding your bike would be the optimal solution.

65
00:03:44,680 --> 00:03:48,920
Of course, in real life you don't have infinite money to maximize performance, and you don't

66
00:03:48,920 --> 00:03:51,600
have unlimited time to minimize spending.

67
00:03:51,600 --> 00:03:54,500
But rather you're trying to find a balance between the two.

68
00:03:54,500 --> 00:03:58,480
So maybe you'd reason that you have an early meeting, and therefore value the time it takes

69
00:03:58,480 --> 00:03:59,680
to get to work.

70
00:03:59,680 --> 00:04:03,940
But you're not independently wealthy, so you care about how much money it takes.

71
00:04:03,940 --> 00:04:09,000
Therefore the optimal solution would be to take your car, or to take the bus.

72
00:04:09,000 --> 00:04:14,060
Now if we wanted a fancy way to mathematically assess which mode of transportation is optimal,

73
00:04:14,060 --> 00:04:18,680
we could set up a function that adds together the travel time and the amount of money that

74
00:04:18,680 --> 00:04:20,620
each option takes.

75
00:04:20,620 --> 00:04:25,480
And then we can set the importance of time versus money with a multiplier.

76
00:04:25,480 --> 00:04:29,260
We'll weight each of these matrices based on our own personal preferences.

77
00:04:29,260 --> 00:04:33,620
We'll call this the cost function, or the objective function.

78
00:04:33,620 --> 00:04:37,160
And you can see that it's heavily influenced by these weighting parameters.

79
00:04:37,160 --> 00:04:41,420
If Q is high, then we're penalizing options that take more time, and if R is high, then

80
00:04:41,420 --> 00:04:44,660
we're penalizing options that cost a lot of money.

81
00:04:44,660 --> 00:04:50,180
And once we set the weights, we calculate the total cost for each option and choose the

82
00:04:50,180 --> 00:04:52,900
one that has the lowest overall cost.

83
00:04:52,900 --> 00:04:55,820
And this is the optimal solution.

84
00:04:55,820 --> 00:04:59,500
And what's interesting about this is that there's different optimal solutions based on

85
00:04:59,500 --> 00:05:02,760
the relative weights you attach to performance and spending.

86
00:05:02,760 --> 00:05:08,420
There's no universal optimal solution, just the best one given the desires of the user.

87
00:05:08,420 --> 00:05:13,400
A CEO might take a helicopter, whereas a college student might ride a bicycle.

88
00:05:13,400 --> 00:05:16,820
But both are optimal given their preferences.

89
00:05:16,820 --> 00:05:21,480
And this is exactly the same kind of reasoning we do when designing a control system.

90
00:05:21,480 --> 00:05:25,860
Rather than think about pole locations, we can think about and assess what is important

91
00:05:25,860 --> 00:05:32,300
to us between how well the system performs and how much we want to spend to get that performance.

92
00:05:32,300 --> 00:05:37,300
Of course, usually how much we want to spend is not measured in dollars, but in actuator effort,

93
00:05:37,300 --> 00:05:39,860
or the amount of energy it takes.

94
00:05:39,860 --> 00:05:44,060
And this is how LQR approaches finding the optimal gain matrix.

95
00:05:44,060 --> 00:05:48,060
We set up a cost function that adds up the weighted sum of performance and effort over

96
00:05:48,060 --> 00:05:49,180
all time.

97
00:05:49,180 --> 00:05:55,000
And then by solving the LQR problem, it returns the gain matrix that produces the lowest cost,

98
00:05:55,000 --> 00:05:57,300
given the dynamics of the system.

99
00:05:57,300 --> 00:06:01,420
Now, the cost function that we use with LQR looks a little different than the function

100
00:06:01,420 --> 00:06:03,540
we developed for the travel example.

101
00:06:03,540 --> 00:06:05,680
But the concept is exactly the same.

102
00:06:05,680 --> 00:06:10,500
We penalize bad performance by adjusting Q, and we penalize actuator effort by adjusting

103
00:06:10,500 --> 00:06:11,880
R.

104
00:06:11,880 --> 00:06:16,440
So let's look at what performance means for this cost function.

105
00:06:16,440 --> 00:06:18,760
Performance is judged on the state vector.

106
00:06:18,760 --> 00:06:23,080
For now, let's assume that we want every state to be zero, to be driven back to its starting

107
00:06:23,080 --> 00:06:24,720
equilibrium point.

108
00:06:24,720 --> 00:06:30,120
So if the system is initialized in some non-zero state, the faster it returns to zero, the better

109
00:06:30,120 --> 00:06:33,100
the performance is, and the lower the cost.

110
00:06:33,100 --> 00:06:37,100
And the way we can get a measure of how quickly it's returning to the desired state is by looking

111
00:06:37,100 --> 00:06:39,320
at the area under the curve.

112
00:06:39,320 --> 00:06:41,320
This is what the integral is doing.

113
00:06:41,320 --> 00:06:46,040
A curve with less area means that it spends more time closer to the goal than a curve with

114
00:06:46,040 --> 00:06:47,320
more area.

115
00:06:47,320 --> 00:06:52,520
However, states can be negative or positive, and we don't want negative values subtracting from

116
00:06:52,520 --> 00:06:53,960
the overall cost.

117
00:06:53,960 --> 00:06:57,240
So we square the value to ensure that it's positive.

118
00:06:57,240 --> 00:07:02,180
This has the effect of punishing larger errors disproportionately more than smaller ones.

119
00:07:02,180 --> 00:07:08,660
But it's a good compromise because it turns our cost function into a quadratic function.

120
00:07:08,660 --> 00:07:13,720
Quadratic functions like z equals x squared plus y squared are convexed, and therefore have

121
00:07:13,720 --> 00:07:15,700
a definite minimum value.

122
00:07:15,700 --> 00:07:20,980
quadratic functions that are subject to linear dynamics remain quadratic, so our system will

123
00:07:20,980 --> 00:07:23,420
also have a definite minimum value.

124
00:07:23,420 --> 00:07:28,580
Lastly, we want to have the ability to weight the relative importance of each state.

125
00:07:28,580 --> 00:07:32,880
And therefore, q isn't a single number, but a square matrix that has the same number of

126
00:07:32,880 --> 00:07:35,360
rows as states.

127
00:07:35,360 --> 00:07:39,960
The q matrix needs to be positive definite so that when we multiply it with the state vectors,

128
00:07:39,960 --> 00:07:43,620
the resulting value is positive and non-zero.

129
00:07:43,620 --> 00:07:48,200
And often it's just a diagonal matrix with positive values along the diagonal.

130
00:07:48,200 --> 00:07:54,680
With this matrix, we can target the states where we want really low error by making the corresponding value in the q

131
00:07:54,680 --> 00:07:56,460
matrix really large.

132
00:07:56,460 --> 00:08:00,880
And the states that we don't care about as much make those values really small.

133
00:08:00,880 --> 00:08:04,260
The other half of the cost function adds up the cost of actuation.

134
00:08:04,260 --> 00:08:08,620
In a very similar fashion, we look at the input vector, and we square the terms to ensure that

135
00:08:08,620 --> 00:08:13,460
they're positive, and then weight them with an r matrix that has positive multipliers along

136
00:08:13,460 --> 00:08:15,400
its diagonal.

137
00:08:15,400 --> 00:08:18,860
We can write this in larger matrix form as follows.

138
00:08:18,860 --> 00:08:23,320
And while you don't see the cost function written like this often, it helps us visualize

139
00:08:23,320 --> 00:08:24,320
something.

140
00:08:24,320 --> 00:08:28,420
q and r are part of this larger weighting matrix.

141
00:08:28,420 --> 00:08:31,680
But the off-diagonal terms of this matrix are zero.

142
00:08:31,680 --> 00:08:37,780
And we can fill in those corners with n, such that the overall matrix is still positive definite,

143
00:08:37,780 --> 00:08:43,440
but now the n matrix penalizes cross products of the input and the state.

144
00:08:43,440 --> 00:08:47,580
Now while there's uses for setting up your cost function with an n matrix, for us we're

145
00:08:47,580 --> 00:08:53,360
going to keep things simple and just set it to zero and focus only on q and r.

146
00:08:53,360 --> 00:08:58,680
So by setting values of q and r, we now have a way to specify exactly what's important to

147
00:08:58,680 --> 00:08:59,680
us.

148
00:08:59,680 --> 00:09:03,220
If one of the actuators is really expensive and we're trying to save energy, then we

149
00:09:03,220 --> 00:09:07,760
penalize it by increasing the r matrix value that corresponds with it.

150
00:09:07,760 --> 00:09:12,040
And this might be the case if you're using thrusters for satellite control, because they use up

151
00:09:12,040 --> 00:09:14,660
fuel, which is a finite resource.

152
00:09:14,660 --> 00:09:21,100
In that case, you may accept a slower reaction or more state error so that you can save fuel.

153
00:09:21,100 --> 00:09:25,120
On the other hand, if performance is really crucial, then we can penalize state error by

154
00:09:25,120 --> 00:09:29,960
increasing the q matrix value that corresponds with the states that we care about.

155
00:09:29,960 --> 00:09:33,900
And this might be the case when using reaction wheels for satellite control, because they

156
00:09:33,900 --> 00:09:38,640
use energy that can be stored in batteries and replenished with the solar panels.

157
00:09:38,640 --> 00:09:44,100
So using more energy for low error control is probably a good tradeoff.

158
00:09:44,100 --> 00:09:46,300
So now the big question.

159
00:09:46,300 --> 00:09:49,440
How do we solve this optimization problem?

160
00:09:49,440 --> 00:09:53,500
I think the big disappointing answer is that deriving the solution is beyond the scope of

161
00:09:53,500 --> 00:09:54,580
this video.

162
00:09:54,580 --> 00:09:57,700
But I left a good link in the description if you want to read up on it.

163
00:09:57,700 --> 00:10:01,900
The good news, however, is that as a control system designer, often the way you approach

164
00:10:01,900 --> 00:10:07,780
LQR design is not by solving the optimization problem by hand, but by developing a linear model

165
00:10:07,780 --> 00:10:13,440
of your system dynamics, then specifying what's important by adjusting the q and r weighting matrices,

166
00:10:13,440 --> 00:10:19,580
then running the LQR command in MATLAB to solve the optimization problem and return the optimal

167
00:10:19,580 --> 00:10:25,160
gain set, and then just simulate the system and adjust q and r again if necessary.

168
00:10:25,160 --> 00:10:30,160
So as long as you understand how q and r affects the closed loop behavior, how they punish state

169
00:10:30,160 --> 00:10:35,820
errors and actuator effort, and you understand that this is a quadratic optimization problem,

170
00:10:35,820 --> 00:10:41,580
then it's relatively simple to use the LQR command in MATLAB to find the optimal gain set.

171
00:10:41,580 --> 00:10:47,300
Now, with LQR, we've moved the design question away from where do we place poles to the question

172
00:10:47,300 --> 00:10:49,300
how do we set q and r.

173
00:10:49,300 --> 00:10:53,460
Unfortunately, there isn't a one-size-fits-all method for choosing these weights.

174
00:10:53,460 --> 00:10:59,280
However, I'd argue that setting q and r is more intuitive than picking pole locations.

175
00:10:59,280 --> 00:11:03,540
For example, you can just start with the identity matrix for both q and r, and then tweak them

176
00:11:03,540 --> 00:11:07,000
through trial and error and intuition about your system.

177
00:11:07,000 --> 00:11:13,720
So to help you develop some of that intuition, let's walk through a few examples in MATLAB.

178
00:11:13,720 --> 00:11:16,380
Alright, this needs a little explanation.

179
00:11:16,380 --> 00:11:18,340
Let's start with the code.

180
00:11:18,340 --> 00:11:22,840
I have a very simple model of a rotating mass in a frictionless environment, and the system

181
00:11:22,840 --> 00:11:26,180
has two states, angle and angular rate.

182
00:11:26,180 --> 00:11:32,000
And I'm designing a full state feedback controller using LQR, and it really couldn't be simpler.

183
00:11:32,000 --> 00:11:37,340
I'll start with the identity matrix for q, where the first diagonal entry is tied to

184
00:11:37,340 --> 00:11:40,720
angular error, and the second is tied to angular rate.

185
00:11:40,720 --> 00:11:46,040
Now, there's only a single actuation input for this system, which are four rotation thrusters

186
00:11:46,040 --> 00:11:50,060
that all act together to create a single torque command.

187
00:11:50,060 --> 00:11:53,140
Therefore r is just a single value.

188
00:11:53,140 --> 00:11:58,480
Now I solve for the optimal feedback gain using the LQR command and build a state space object

189
00:11:58,480 --> 00:12:01,360
that represents the closed loop dynamics.

190
00:12:01,360 --> 00:12:05,240
With the controller designed, I can simulate the response to an initial condition, which

191
00:12:05,240 --> 00:12:07,660
I'm setting to 3 radians.

192
00:12:07,660 --> 00:12:09,980
And that's pretty much the whole thing.

193
00:12:09,980 --> 00:12:13,660
Everything else in this script just makes this fancy plot so that it's easier to comprehend

194
00:12:13,660 --> 00:12:14,660
the results.

195
00:12:14,660 --> 00:12:17,660
Alright, let's run this script.

196
00:12:17,660 --> 00:12:22,320
You can see the UFO gets initialized to 3 radians, as promised.

197
00:12:22,320 --> 00:12:26,300
And up at the top I'm keeping track of how long the maneuver takes, which is representative

198
00:12:26,300 --> 00:12:30,980
of the performance, and how much fuel is used to complete the maneuver.

199
00:12:30,980 --> 00:12:34,920
So let's kick it off and see how well the controller does.

200
00:12:43,980 --> 00:12:44,980
Hey, look at that.

201
00:12:44,980 --> 00:12:51,220
It completed the maneuver in 5.8 seconds with 15 units of fuel, and it got the cow in the

202
00:12:51,220 --> 00:12:54,220
process, which is the important part.

203
00:12:54,220 --> 00:12:59,680
When the thrusters are active, they generate a torque that accelerates the UFO over time.

204
00:12:59,680 --> 00:13:03,660
Therefore fuel usage is proportional to the integral of acceleration.

205
00:13:03,660 --> 00:13:07,640
So the longer we accelerate, the more fuel is used.

206
00:13:07,640 --> 00:13:12,700
Now let's see if we can use less fuel for this maneuver by penalizing the thruster more.

207
00:13:12,700 --> 00:13:18,160
I'll bump R up to 2 and rerun the simulation.

208
00:13:18,160 --> 00:13:35,640
Well, we used two fewer units of fuel, but at the expense of over 3 additional seconds.

209
00:13:35,640 --> 00:13:40,420
The problem is that with this combination, it overshot the target just a bit and had to waste

210
00:13:40,420 --> 00:13:42,200
time coming back.

211
00:13:42,200 --> 00:13:46,320
So let's try to slow down the max rotation speed with the hope that it won't overshoot.

212
00:13:46,320 --> 00:13:51,080
And we're going to do that by penalizing the angular rate portion of the Q matrix.

213
00:13:51,080 --> 00:13:55,260
Now any non-zero rate costs double what it did before.

214
00:13:55,260 --> 00:14:07,020
And let's give this a shot.

215
00:14:07,020 --> 00:14:11,820
Well we saved about a second since it didn't overshoot, and in the process managed to knock

216
00:14:11,820 --> 00:14:14,700
another unit of fuel off.

217
00:14:14,700 --> 00:14:16,580
Alright enough of this small stuff.

218
00:14:16,580 --> 00:14:28,180
Let's really save fuel now by relaxing the angle error weight a bunch.

219
00:14:28,180 --> 00:14:33,540
Okay this is going really slowly now, so let me speed up the video to just get through it.

220
00:14:33,540 --> 00:14:37,700
In the end we used 5 units of fuel, less than half of what was used before.

221
00:14:37,700 --> 00:14:42,580
And we can go the other way as well and tune a really aggressive controller.

222
00:14:42,580 --> 00:14:46,540
Okay yeah, that's much faster.

223
00:14:46,540 --> 00:14:50,040
Less than 2 seconds and our acceleration is off the charts.

224
00:14:50,040 --> 00:14:52,580
That's how you rotate to pick up a cow.

225
00:14:52,580 --> 00:14:58,580
Unfortunately it's at the expense of almost 100 units of fuel, so there's downsides to everything.

226
00:14:58,580 --> 00:15:02,860
Alright, so hopefully you're starting to see how we can tweak and tune our controller by

227
00:15:02,860 --> 00:15:04,880
adjusting these two matrices.

228
00:15:04,880 --> 00:15:07,400
And it's pretty simple.

229
00:15:07,400 --> 00:15:11,460
Now I know this video is dragging on, but with a different script I want to show you one

230
00:15:11,460 --> 00:15:12,900
more thing real quickly.

231
00:15:12,900 --> 00:15:17,060
And that's how LQR is more powerful than pole placement.

232
00:15:17,060 --> 00:15:21,960
Here I have a different state space model, one that has 3 states in a single actuator.

233
00:15:21,960 --> 00:15:25,880
And I've defined my Q and R matrices and solved for the optimal gain.

234
00:15:25,880 --> 00:15:29,840
And like before I'll generate the closed loop state space model, and then run the response

235
00:15:29,840 --> 00:15:32,860
to an initial condition of 1, 0, 0.

236
00:15:32,860 --> 00:15:38,880
I then plot the response of the first state, that step from 1 back to 0, the actuator effort,

237
00:15:38,880 --> 00:15:42,040
and the location of the closed loop poles and zeros.

238
00:15:42,040 --> 00:15:46,120
So let's run this and see what happens.

239
00:15:46,120 --> 00:15:51,700
Well the first state tracks back to 0 nicely, but at the expense of a lot of actuation.

240
00:15:51,700 --> 00:15:56,320
Now I didn't model anything in particular, but let's say that the actuator effort is thrust

241
00:15:56,320 --> 00:15:57,320
required.

242
00:15:57,320 --> 00:16:00,380
So this controller is requesting 10 units of thrust.

243
00:16:00,380 --> 00:16:04,360
However, let's say our thruster is only capable of 2 units of thrust.

244
00:16:04,360 --> 00:16:08,480
This controller design would saturate the thruster, and we wouldn't get the response that we're

245
00:16:08,480 --> 00:16:09,480
looking for.

246
00:16:09,480 --> 00:16:13,940
Now, had we developed this controller using pole placement, the question at this point

247
00:16:13,940 --> 00:16:19,860
would be which of these 3 poles should we move in order to reduce the actuator effort?

248
00:16:19,860 --> 00:16:22,800
And that's not too intuitive, right?

249
00:16:22,800 --> 00:16:28,360
But with LQR we can easily go to the R matrix and penalize actuator usage by raising a single

250
00:16:28,360 --> 00:16:29,360
value.

251
00:16:29,360 --> 00:16:32,100
And I'll re-run the script.

252
00:16:32,100 --> 00:16:37,560
We see that the response is slower as expected, but the actuator is no longer saturated.

253
00:16:37,560 --> 00:16:38,860
And check this out.

254
00:16:38,860 --> 00:16:44,600
All 3 closed loop poles moved with this single adjustment of R. So if we were using pole placement,

255
00:16:44,600 --> 00:16:48,760
we would have had to know how to move these poles just like this in order to reduce the

256
00:16:48,760 --> 00:16:50,360
actuator effort.

257
00:16:50,360 --> 00:16:52,620
And that would be pretty tough.

258
00:16:52,620 --> 00:16:55,040
So that's where I want to leave this video.

259
00:16:55,040 --> 00:16:59,780
LQR control is pretty powerful, and hopefully you saw that it's simple to set up and relatively

260
00:16:59,780 --> 00:17:01,940
intuitive to tune and tweak.

261
00:17:01,940 --> 00:17:07,040
And the best part is that it returns an optimal gain matrix based on how you weight, performance,

262
00:17:07,040 --> 00:17:07,960
and effort.

263
00:17:07,960 --> 00:17:10,780
So it's up to you how you want your system to behave in the end.

264
00:17:10,780 --> 00:17:14,560
Now if you don't want to miss the next Tech Talk video, don't forget to subscribe to this

265
00:17:14,560 --> 00:17:15,560
channel.

266
00:17:15,560 --> 00:17:19,400
Also if you want to check out my channel, Control System Lectures, I cover more control theory

267
00:17:19,400 --> 00:17:20,840
topics there as well.

268
00:17:20,840 --> 00:17:22,900
Thanks for watching and I'll see you next time.

